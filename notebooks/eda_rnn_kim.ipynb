{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cac72ae-9be5-43d4-87d3-b2319a0f757b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning Time Series COVID-19 Cases Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a246bb7-0cdf-4939-a4e9-870f871706f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd5297-79e4-4864-bb68-8deb37dbc70a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dependencies importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c99354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload imported module every time a jupyter cell is executed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de425903-9365-4407-8ae8-9b20a6e41dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import requests\n",
    "import pandas_profiling\n",
    "from typing import overload\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop \n",
    "from covid_time_series_prediction.ml_logic import preprocessor\n",
    "# from ml_logic.country_data import country_output\n",
    "from covid_time_series_prediction.ml_logic.preprocessor import train_test_set, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332849e5-8682-4079-8266-8a22c70d7d38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee22a40-a282-4e4f-bf18-ce8a7633b59c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e9b20-7339-486d-8ebc-21b0394c5e5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### By country over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c36f91-5db2-4aa7-b598-45ae52f2dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_time_series(feature='stringency', start_date='2020-02-14', end_date='2021-02-14'):\n",
    "#     \"\"\"\n",
    "#     Get stringency time series for each countries requesting API.\n",
    "#     Returns json dict with TS between start_date and end_date like 'YYYY-MM-DD'.\n",
    "#     \"\"\"\n",
    "#     url = f'https://covidtrackerapi.bsg.ox.ac.uk/api/v2/{feature}/date-range/{start_date}/{end_date}'\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         return ''\n",
    "#     data = response.json()\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f6689-5b7f-42e3-891b-57367b4658e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries_time_series_api = fetch_time_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6bad4c-3c99-4620-aead-b7951a993db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(k, [c for c in v if c == 'VNM'])  for k, v in countries_time_series_api.items()  if k == 'countries' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59acb5e4-2aee-4aa5-be96-ac8af9d3a96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [([([([(vee)  for kaaa, veee  in vee.items() if kaaa in ['date_value', 'confirmed']  ])  for kaa, vee  in ve.items() if kaa =='VNM'   ])  for ka, ve  in v.items() ])  for k, v in countries_time_series_api.items() if k=='data'   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb51b76-85af-4077-8db0-4b74529104a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [(k, [(ka, [(kaa, vee)  for kaa, vee  in ve.items() if kaa =='USA'   ])  for ka, ve  in v.items() ])  for k, v in countries_time_series_api.items() if k=='data'   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b518b601-27e8-4411-9b10-165c94c89c3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Country data for a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e858c-c9e9-4d78-9d94-804e06fbf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_data(country='USA', date='2020-08-14'):\n",
    "#     \"\"\"\n",
    "#     Get stringency data for one country {ALPHA-3} requesting API.\n",
    "#     Returns json dict with data for country like 'AAA' and specific date and like 'YYYY-MM-DD'.\n",
    "#     \"\"\"\n",
    "#     url = f'https://covidtrackerapi.bsg.ox.ac.uk/api/v2/stringency/actions/{country}/{date}'\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         return ''\n",
    "#     data = response.json()\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0debbac8-54a8-482a-b339-d5fa249c4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# country_data_api = fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c13eee-1681-40ca-b0d2-2ab21437191f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[';'.join([str(kk) for kk, vv in d.items()]) for i, d in enumerate(v) if type(d) == dict and i == 0] for v in country_data_api.values()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81f0b8-9fc7-4e38-8e24-99408857cb90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [[';'.join([str(vv) for kk, vv in d.items()]) for d in v if type(d) == dict] for v in country_data_api.values()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869ee50-edb3-423d-8a75-f05af3f32afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # [';'.join([str(vv) for vv in v]) for v in country_data_api.values()][-1]\n",
    "# [';'.join([str(kk) for kk in v]) for k, v in country_data_api.items()][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad4771-e464-4eb1-86f5-c5c480cea8d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1591b-31c5-4a38-b0fb-4bfaec0924f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Data project directory\n",
    "# data_dir = '../data/raw_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7c791-f898-4106-b9a9-f1221fcfb1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Read URL**, **Get CSV files** and **store CSV in local**  *(optional do it at begining or to refresh CSV data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318d9af-8148-4bbc-9dff-7359600f778d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **get_database_to_csv()** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d42cd6c-5efd-4cad-b74b-d134e2653dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_database_to_csv(url, csv_list, path='', db_grid=[]) -> list:\n",
    "#     \"\"\"\n",
    "#     function that take in parameter:\n",
    "#      - a root URL (string) to get the CSV data,\n",
    "#      - a list of CSV files,\n",
    "#      - a path (string) to store CSV in local,\n",
    "#      - a grid (list of list) to add in the CSV filename, URL, local path.     \n",
    "#     and returns the gird updated with the CSVs of the list\n",
    "    \n",
    "#     \"\"\"\n",
    "\n",
    "#     ### Create a database grid (list of list) with all CSVs and associated URLs\n",
    "#     # print('db_grid', db_grid)\n",
    "#     #### Data project directory (if empty do not store CSV in local)\n",
    "#     # print('path', path)\n",
    "#     ### Website CSV datasets URL\n",
    "#     # print('url', url)\n",
    "#     #### List of CSVs of Website to retrieve\n",
    "#     # print('csv_list', csv_list)\n",
    "\n",
    "#     #### Length of grid aka number of CSVs already stored in grid\n",
    "#     len_grid = len(db_grid)\n",
    "\n",
    "#     for l in range(len(csv_list)):\n",
    "#         sub_list = []       \n",
    "#         sub_list.append(csv_list[l]) ## 1st pos°: CSV filename\n",
    "#         sub_list.append(url + csv_list[l]) ## 2nd pos°: URL + CSV\n",
    "#         if len(data_dir) > 0: ## store CSV in local\n",
    "#             sub_list.append(data_dir + csv_list[l]) ## 3rd pos°: local data path + CSV\n",
    "#             !curl -L \"{url + csv_list[l]}\" > {data_dir + csv_list[l]} ## curl <URL>/<CSV> => <path>\n",
    "#         # print('sub_list', sub_list)\n",
    "#         db_grid.append(sub_list)\n",
    "\n",
    "#     ### Return a database grid (list of list) with all CSVs and associated URLs\n",
    "#     return db_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa98a-c3ba-4108-98bd-5a0b4af0cd17",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Get database to csv** with **get_database_to_csv()** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62c742-44a6-46c0-bfca-d5fece235ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### Oxford Master data time series URL\n",
    "# url_root_oxford = 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/'\n",
    "\n",
    "# #### List of CSVs of Oxford database Feel free to add more feature...\n",
    "# ## index_strigency missed!\n",
    "# ## 'E3;Fiscal measures;' missed!\n",
    "# ## 'E4;International support;' missed!\n",
    "# ## 'H3;Contact tracing;' missed!\n",
    "# ## 'H4;Emergency investment in healthcare!\n",
    "# ## 'H5;Investment in vaccines missed!\n",
    "# ## 'V1;Vaccine Prioritisation missed!\n",
    "# ## 'V2;Vaccine Availability missed!\n",
    "# ## 'V3;Vaccine Financial Support!\n",
    "# ## 'V4;Mandatory Vaccination missed!\n",
    "# csv_list = ['confirmed_cases.csv', 'confirmed_deaths.csv',\n",
    "#             'government_response_index_avg.csv', 'stringency_index_avg.csv', \n",
    "#             'containment_health_index_avg.csv', 'economic_support_index.csv',\n",
    "#             'c1m_school_closing.csv', 'c2m_workplace_closing.csv',\n",
    "#             'c3m_cancel_public_events.csv', 'c4m_restrictions_on_gatherings.csv', \n",
    "#             'c5m_close_public_transport.csv', 'c6m_stay_at_home_requirements.csv',\n",
    "#             'c7m_movementrestrictions.csv', 'c8ev_internationaltravel.csv',\n",
    "#             'e1_income_support.csv', 'e2_debtrelief.csv',\n",
    "#             'h1_public_information_campaigns.csv', 'h2_testing_policy.csv',\n",
    "#             'h3_contact_tracing.csv', 'h6m_facial_coverings.csv',\n",
    "#             'h7_vaccination_policy.csv', 'h8m_protection_of_elderly_ppl.csv'\n",
    "#            ] ## ; print('csv_list', csv_list, 'len(csv_list)', len(csv_list))\n",
    "    \n",
    "# ### Vacinations Dataset URLs\n",
    "# url_root_vaccinations = 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/'\n",
    "\n",
    "# #### List of CSVs of Vaccinations database\n",
    "# csv_list_vax = ['vaccinations.csv', 'vaccinations-by-age-group.csv'] ## ; print('csv_list', csv_list_vax, 'len(csv_list)', len(csv_list_vax))\n",
    "\n",
    "# ### Create a database grid all CSVs and associated URLs from Oxford website\n",
    "# db_grid = get_database_to_csv(url_root_oxford, csv_list, data_dir)\n",
    "# ### Insert into database grid all CSVs and associated URLs from vaccinations website\n",
    "# db_grid = get_database_to_csv(url_root_vaccinations, csv_list_vax, data_dir, db_grid)\n",
    "# # print('db_grid', db_grid)\n",
    "\n",
    "# # Stack all csl in the list\n",
    "# csv_list += csv_list_vax ## ; print('csv_list', csv_list)\n",
    "\n",
    "# # transform list into dict:\n",
    "# csv = dict(zip(csv_list, [v[0] for v in enumerate(csv_list)])) ## ; print ('csv', csv) ## if v[1] == 'containment_health_index_avg.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c8b3bb-c12b-43a3-9dda-7bbd905f3622",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d5c4a-c489-4204-a782-08cfb9a127c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc67099-9098-47c4-9e1d-b2754e07cd70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Read CSV** and **Set raw dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d45ada",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Read raw CSV** and **Set dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_gov_response = pd.read_csv(data_dir + 'government_response_index_avg.csv')\n",
    "df_raw_health = pd.read_csv(data_dir + 'containment_health_index_avg.csv')\n",
    "df_raw_economic = pd.read_csv(data_dir + 'economic_support_index.csv')\n",
    "\n",
    "#### Vaccination\n",
    "df_raw_vaccination = pd.read_csv(data_dir + 'vaccinations.csv')\n",
    "df_raw_ages = pd.read_csv(data_dir + 'vaccinations-by-age-group.csv')\n",
    "\n",
    "\n",
    "#### Data Frame target\n",
    "df_raw_cases = pd.read_csv(data_dir + 'confirmed_cases.csv')\n",
    "df_raw_deaths = pd.read_csv(data_dir + 'confirmed_deaths.csv')\n",
    "\n",
    "#### Data multiple\n",
    "df_raw_school_closing=pd.read_csv(data_dir + 'c1m_school_closing.csv')\n",
    "df_raw_workplace_closing=pd.read_csv(data_dir + 'c2m_workplace_closing.csv')\n",
    "df_raw_cancel_public_event=pd.read_csv(data_dir + 'c3m_cancel_public_events.csv')\n",
    "df_raw_restriction_on_gathering=pd.read_csv(data_dir + 'c4m_restrictions_on_gatherings.csv')\n",
    "df_raw_stay_at_home=pd.read_csv(data_dir + 'c6m_stay_at_home_requirements.csv')\n",
    "df_raw_international_travel=pd.read_csv(data_dir + 'c6m_stay_at_home_requirements.csv')\n",
    "df_raw_goverment_response=pd.read_csv(data_dir + 'government_response_index_avg.csv')\n",
    "df_raw_facial_covering=pd.read_csv(data_dir + 'h6m_facial_coverings.csv')\n",
    "df_raw_vacination_policy=pd.read_csv(data_dir + 'h7_vaccination_policy.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f43d38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **Read out CSV** and **Set dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647dd56-8eaf-4f56-b52f-173e818e245c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #### CSV Data out project directory\n",
    "# csv_dir = '../data/csv_out/'\n",
    "# # ! unzip {csv_dir}usa_index\n",
    "# # ! unzip {csv_dir}usa_indicator\n",
    "# # ! rm ECG_data.zip\n",
    "# df_usa_index =  pd.read_csv(csv_dir + 'usa_index.csv')\n",
    "# df_usa_indicator =  pd.read_csv(csv_dir + 'usa_indicator.csv')\n",
    "# df_usa_index, df_usa_indicator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecf123-5e8d-4e1e-b337-e0164c78fa4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DataFrames setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81ed76f-6978-4e8d-84a6-41b4cd8cb4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sumedha csv test\n",
    "# df_ts_usa_index =  df_usa_index.copy()\n",
    "# df_ts_usa_indicator =  df_usa_indicator.copy()\n",
    "\n",
    "# df_ts_usa_index.head(), df_ts_usa_indicator.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780e433-b780-4736-9011-36e69a97910d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Time series analysing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b05ade-58d9-4909-85f7-270a32dc2480",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Time Series Analysis *(optional)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9490e09-78eb-4563-881a-ea7d9f40b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cases = df_raw_cases.drop(columns=['country_name','region_code','region_name','jurisdiction','Unnamed: 0'])\n",
    "# ts_cases = ts_cases.groupby('country_code').agg('sum')\n",
    "# ts_cases.transpose()\n",
    "# ts_cases.columns.name = 'Dates'\n",
    "# ts_cases = ts_cases.fillna(0)\n",
    "# # ts_cases.index = pd.to_datetime(ts_cases.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9518a-a848-45c5-b0cf-a1dc2363b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cases = ts_cases.transpose()\n",
    "# ts_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e0fb8-f976-4dbe-8243-7a69be38b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5ecb3-6362-430f-bdc8-f8f2298c120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vn_ts_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54395e-6a75-45b7-a389-7f739b5c35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vn_ts_cases = vn_ts_cases.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca627f6-23e4-4243-8a68-e0b3108b21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw_cases.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75735fc5-e04d-46ae-9d96-92dccdc1aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get VietNam country dataset\n",
    "# vn_data = df_raw_cases.loc[df_raw_cases['country_code'] == 'VNM'].copy()\n",
    "\n",
    "# vn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f336df2-286a-4819-a011-c1ae0d7cdb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# vn_data.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122911e-70c8-4131-bf2f-8db270b3ac93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TENSORFLOW & RNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636afbb-aab0-4500-897b-311961289203",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Recurrent Neural Network (sequences data) modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f081b-7ee6-405b-8e13-04bf267ac2e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Samples/Sequences, Observations, Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6427dc3-25b3-4a5a-abba-20e92d67ab1b",
   "metadata": {},
   "source": [
    "X.shape = (n_SEQUENCES, n_OBSERVATIONS, n_FEATURES) and y = RNN(X) where $X_{i,j}^{t}$\n",
    "\n",
    "with $_{i}$ is the sample/sequence, $_{j}$ is the feature measured and  $^{t}$ is the time at which the observation is seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8151dc-1f0e-4981-91a0-c1164230af26",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- **retrieve dataset** from Sumedha & Alberto\n",
    "\n",
    "    - **clean dataset**: \n",
    "        \n",
    "        - **drop first lines == 0** *(before Covid arrived)*\n",
    "        \n",
    "        - **check Nan**: \n",
    "- **strategy 1 country by country** sequences split as follow:\n",
    "\n",
    "- **strategy 2 one sequence per country**:\n",
    "    - **split X train, set** \n",
    "    - **Pad sequences**\n",
    "    - **create one csv per country**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32848eaa-a889-47ee-972c-e9f2e54214cc",
   "metadata": {},
   "source": [
    "## Training strategies:\n",
    "- Get NB dataset (cleaned) from Alberto & Sumedha\n",
    "- 1/ Indicator in precentage %\n",
    "- 2/ Indicator as categorical labels\n",
    "- Run same RNN model in parallel with Kim & Thomas\n",
    "- Identify best dataset\n",
    "- Parameters to fit:\n",
    "    - increase **nb of sequences**\n",
    "    - train series modulation (ex: [50, 150, 200, 300, 400 nb of days = n_obs]) < take time to compute\n",
    "    - **learning_rate** in Optimizer(parameters)\n",
    "    - model layers architecture (**simple** -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "        > LSTM\n",
    "        > Dense\n",
    "       (> LSTM\n",
    "        > LSTM\n",
    "        > Dense)\n",
    "     >> **try to overfit** the model with the loss (train over val) or (early_stopping)\n",
    "     >> **(X_val, y_val)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4cdbb-56aa-4522-84a6-833471a7b34a",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ee15a-c507-4049-9489-1f546a1f0a8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time Series **Analysis** & **Preparation** to training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775435d-8b7a-4742-bcb2-a76e1c2ffb1c",
   "metadata": {},
   "source": [
    "# Alberto's RNN model #4 Starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "648961ed-ee19-4342-b137-8f5029082404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 60, 20)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alberto train set\n",
    "n_seq = 200 ## nb of sequences (samples)\n",
    "n_obs = 60 # maxi = 96 (stay around 70 or more test_split)\n",
    "n_feat = 20 #  X_train.shape[1] # 20 feature:\n",
    "n_pred = 1 # nb of days where we can predict new daily deaths\n",
    "n_seq, n_obs, n_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245d337-90d7-47b1-a4ee-b508e8731c39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Splitting\n",
    "\n",
    "Split the dataset into training, validation, and test datasplit the dataset into training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4fe70c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 2, 1, 2, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alberto train set\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_set('France', split_train=0.7, split_val=0.9)\n",
    "np.ndim(X_train), np.ndim(y_train), np.ndim(X_val), np.ndim(y_val), np.ndim(X_test), np.ndim(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4fba2-9562-49eb-9b94-7c5ab57fd163",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create sequences (`X`,`y`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e6437-7538-4c29-b8d9-d00d4d804064",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Generates an entire dataset of multiple subsamples with shape $(X, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55b0cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_sequence(X, y, X_len, y_len) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given the initial dataframe `df`, return a shorter dataframe sequence of length `length` (eg n_obs).\n",
    "    This shorter sequence should be selected at random\n",
    "    \"\"\"\n",
    "    X_y_len = X_len + y_len\n",
    "    print('_len + y_len',  X_len,  y_len)\n",
    "    print('X.shape[0] >= X_y_len', X.shape[0], X_y_len)\n",
    "    if X.shape[0] >= X_y_len:\n",
    "        last_possible = X.shape[0] - X_y_len\n",
    "    else:\n",
    "        last_possible = X.shape[0]\n",
    "        print('X_y_len = ?', X.shape[0])\n",
    "    # How to split sequences? we could do it manually...\n",
    "    print('X.shape[0]', X.shape[0])\n",
    "    random_start = np.random.randint(0, last_possible)\n",
    "    # X start and y end\n",
    "    X_sample = X[random_start : random_start + X_len]\n",
    "    y_sample = y[random_start + X_len : (random_start + X_y_len)]\n",
    "    print(\"X[random_start : random_start + X_len]\", f\"X[{random_start} : {random_start + X_len}]\")\n",
    "    print(\"y[random_start : random_start + X_y_len]\", f\"y[{random_start} : {(random_start + X_y_len)}]\")\n",
    "    \n",
    "    return np.array(X_sample), np.array(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a54ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1993c868-606c-4d31-ac8d-997bc85d63d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[174 : 234]\n",
      "y[random_start : random_start + X_y_len] y[174 : 235]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60, 20), (1,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it\n",
    "(X_sample, y_sample) = subsample_sequence(X_train, y_train, X_len=n_obs, y_len=n_pred) # n_seq = 200, n_obs = 150\n",
    "X_sample.shape, y_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb0927-e52b-4d41-8dcb-6ca6f204a1f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **get_X_y(df, n_sequences, length)**\n",
    "\n",
    "function to generates an entire dataset of multiple subsamples suitable for RNN, that is, $(X, y)$ of shape:\n",
    "\n",
    "```python\n",
    "X.shape = (n_sequences, length, n_features)\n",
    "y.shape = (n_sequences, )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d2b3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no use\n",
    "# def get_X_y(df, n_sequences, length, feature='VNM') -> tuple:\n",
    "#     '''Return a list of samples (X, y)'''\n",
    "#     X, y = [], []\n",
    "\n",
    "#     for i in range(n_sequences):\n",
    "#         (xi, yi) = split_subsample_sequence(df, length, feature=feature)\n",
    "#         X.append(xi)\n",
    "#         y.append(yi)\n",
    "        \n",
    "#     X = np.array(X)\n",
    "#     y = np.array(y)\n",
    "\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15128c-961a-471e-b864-589455120c15",
   "metadata": {},
   "source": [
    "def get_X_y(X_train, y_train, X_test, y_test, X_len, y_len, n_seq_train, X_val=np.array(range(1)), y_val=np.array(range(1))) -> tuple:\n",
    "    '''Return a list of samples (X, y)'''\n",
    "    X_train_list = X_val_list = X_test_list = y_list = y_val = y_test = []\n",
    "    # train sequences splitting\n",
    "    for i in range(n_sequences):\n",
    "        # print('X_len', X_len, 'y_len', y_len)\n",
    "        (x_tainr_i, y_train_i) = subsample_sequence(X, y, X_len=X_len, y_len=y_len)\n",
    "        X_list.append(xi)\n",
    "        y_list.append(yi)\n",
    "    X_train_array = np.array(X_list)\n",
    "    y_train_array = np.array(y_list) \n",
    "\n",
    "    if X_val==np.array(range(1)) and y_val==np.array(range(1)):\n",
    "        # val sequences splitting (train / val /test)        \n",
    "        n_seq_val = n_seq_train // 5 # number of sequences in test set ?\n",
    "        n_seq_test = n_seq_train // 10 # number of sequences in test set ?\n",
    "        for i in range(n_s_train):\n",
    "            # print('X_len', X_len, 'y_len', y_len)\n",
    "            (xi, yi) = subsample_sequence(X, y, X_len=X_len, y_len=y_len)\n",
    "            X_list.append(xi)\n",
    "            y_list.append(yi)\n",
    "        X_val_array = np.array(X_list)\n",
    "        y_val_array = np.n_seq_test(y_list) \n",
    "        for i in range(n_seq_val):\n",
    "            # print('X_len', X_len, 'y_len', y_len)\n",
    "            (xi, yi) = subsample_sequence(X, y, X_len=X_len, y_len=y_len)\n",
    "            X_list.append(xi)\n",
    "            y_list.append(yi)\n",
    "        X_test_array = np.array(X_list)\n",
    "        y_test_array = np.array(y_list) \n",
    "        return X_train_array, y_train_array, X_val_array, y_val_array, X_test_array, y_test_array\n",
    "    else:\n",
    "        # test sequences splitting (train / test)\n",
    "        n_seq_test = n_seq_train // 5 # number of sequences in test set ?\n",
    "        for i in range(n_sequences):\n",
    "            # print('X_len', X_len, 'y_len', y_len)\n",
    "            (x_tainr_i, y_train_i) = subsample_sequence(X, y, X_len=X_len, y_len=y_len)\n",
    "            X_list.append(xi)\n",
    "            y_list.append(yi)\n",
    "        X_test_array = np.array(X_list)\n",
    "        y_test_array = np.array(y_list)        \n",
    "        return X_train_array, y_train_array, X_test_array, y_test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3cde1f94-64b6-472d-8007-5a91ec085172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_2(X, y, X_len, y_len, n_sequences) -> tuple:\n",
    "    '''Return a list of samples (X, y)'''\n",
    "    X_list, y_list = [], []\n",
    "\n",
    "    for i in range(n_sequences):\n",
    "        (xi, yi) = subsample_sequence(X, y, X_len=X_len, y_len=y_len)\n",
    "        X_list.append(xi)\n",
    "        y_list.append(yi)\n",
    "        \n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9096e3f-477e-45ae-a9a2-bdb1c8163ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 40, 20)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seq_val = n_seq // 5 # number of sequences in test set ?\n",
    "n_seq_test = n_seq // 10 # number of sequences in test set ?\n",
    "n_seq, n_seq_val, n_seq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1682240c-818e-4e96-9a2a-8b596cd235bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97, 20), (97,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c3af4e7e-d602-4fcd-a36a-942ab4dc0b72",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[28 : 88]\n",
      "y[random_start : random_start + X_y_len] y[28 : 89]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[11 : 71]\n",
      "y[random_start : random_start + X_y_len] y[11 : 72]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[13 : 73]\n",
      "y[random_start : random_start + X_y_len] y[13 : 74]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[8 : 68]\n",
      "y[random_start : random_start + X_y_len] y[8 : 69]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[10 : 70]\n",
      "y[random_start : random_start + X_y_len] y[10 : 71]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[28 : 88]\n",
      "y[random_start : random_start + X_y_len] y[28 : 89]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[22 : 82]\n",
      "y[random_start : random_start + X_y_len] y[22 : 83]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[26 : 86]\n",
      "y[random_start : random_start + X_y_len] y[26 : 87]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[6 : 66]\n",
      "y[random_start : random_start + X_y_len] y[6 : 67]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[11 : 71]\n",
      "y[random_start : random_start + X_y_len] y[11 : 72]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[31 : 91]\n",
      "y[random_start : random_start + X_y_len] y[31 : 92]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[3 : 63]\n",
      "y[random_start : random_start + X_y_len] y[3 : 64]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[8 : 68]\n",
      "y[random_start : random_start + X_y_len] y[8 : 69]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[21 : 81]\n",
      "y[random_start : random_start + X_y_len] y[21 : 82]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[3 : 63]\n",
      "y[random_start : random_start + X_y_len] y[3 : 64]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[27 : 87]\n",
      "y[random_start : random_start + X_y_len] y[27 : 88]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[9 : 69]\n",
      "y[random_start : random_start + X_y_len] y[9 : 70]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[4 : 64]\n",
      "y[random_start : random_start + X_y_len] y[4 : 65]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[13 : 73]\n",
      "y[random_start : random_start + X_y_len] y[13 : 74]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 97 61\n",
      "X.shape[0] 97\n",
      "X[random_start : random_start + X_len] X[12 : 72]\n",
      "y[random_start : random_start + X_y_len] y[12 : 73]\n",
      "X_test.shape, y_test.shape, n_seq_test, n_obs, n_feat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20, 60, 20), (20, 1), 20, 60, 20)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = get_X_y_2(X_test, y_test, X_len=n_obs, y_len=n_pred, n_sequences=n_seq_test)\n",
    "print('X_test.shape, y_test.shape, n_seq_test, n_obs, n_feat')\n",
    "X_test.shape, y_test.shape, n_seq_test, n_obs, n_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "497196a7-2d6a-4663-82a9-c8873c4ad0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[64 : 124]\n",
      "y[random_start : random_start + X_y_len] y[64 : 125]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[10 : 70]\n",
      "y[random_start : random_start + X_y_len] y[10 : 71]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[0 : 60]\n",
      "y[random_start : random_start + X_y_len] y[0 : 61]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[84 : 144]\n",
      "y[random_start : random_start + X_y_len] y[84 : 145]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[69 : 129]\n",
      "y[random_start : random_start + X_y_len] y[69 : 130]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[27 : 87]\n",
      "y[random_start : random_start + X_y_len] y[27 : 88]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[59 : 119]\n",
      "y[random_start : random_start + X_y_len] y[59 : 120]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[69 : 129]\n",
      "y[random_start : random_start + X_y_len] y[69 : 130]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[19 : 79]\n",
      "y[random_start : random_start + X_y_len] y[19 : 80]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[58 : 118]\n",
      "y[random_start : random_start + X_y_len] y[58 : 119]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[107 : 167]\n",
      "y[random_start : random_start + X_y_len] y[107 : 168]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[45 : 105]\n",
      "y[random_start : random_start + X_y_len] y[45 : 106]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[73 : 133]\n",
      "y[random_start : random_start + X_y_len] y[73 : 134]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[33 : 93]\n",
      "y[random_start : random_start + X_y_len] y[33 : 94]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[51 : 111]\n",
      "y[random_start : random_start + X_y_len] y[51 : 112]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[60 : 120]\n",
      "y[random_start : random_start + X_y_len] y[60 : 121]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[3 : 63]\n",
      "y[random_start : random_start + X_y_len] y[3 : 64]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[11 : 71]\n",
      "y[random_start : random_start + X_y_len] y[11 : 72]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[2 : 62]\n",
      "y[random_start : random_start + X_y_len] y[2 : 63]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[16 : 76]\n",
      "y[random_start : random_start + X_y_len] y[16 : 77]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[9 : 69]\n",
      "y[random_start : random_start + X_y_len] y[9 : 70]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[90 : 150]\n",
      "y[random_start : random_start + X_y_len] y[90 : 151]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[91 : 151]\n",
      "y[random_start : random_start + X_y_len] y[91 : 152]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[113 : 173]\n",
      "y[random_start : random_start + X_y_len] y[113 : 174]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[0 : 60]\n",
      "y[random_start : random_start + X_y_len] y[0 : 61]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[59 : 119]\n",
      "y[random_start : random_start + X_y_len] y[59 : 120]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[74 : 134]\n",
      "y[random_start : random_start + X_y_len] y[74 : 135]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[77 : 137]\n",
      "y[random_start : random_start + X_y_len] y[77 : 138]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[96 : 156]\n",
      "y[random_start : random_start + X_y_len] y[96 : 157]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[110 : 170]\n",
      "y[random_start : random_start + X_y_len] y[110 : 171]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[83 : 143]\n",
      "y[random_start : random_start + X_y_len] y[83 : 144]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[6 : 66]\n",
      "y[random_start : random_start + X_y_len] y[6 : 67]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[14 : 74]\n",
      "y[random_start : random_start + X_y_len] y[14 : 75]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[30 : 90]\n",
      "y[random_start : random_start + X_y_len] y[30 : 91]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[45 : 105]\n",
      "y[random_start : random_start + X_y_len] y[45 : 106]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[119 : 179]\n",
      "y[random_start : random_start + X_y_len] y[119 : 180]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[34 : 94]\n",
      "y[random_start : random_start + X_y_len] y[34 : 95]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[27 : 87]\n",
      "y[random_start : random_start + X_y_len] y[27 : 88]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[109 : 169]\n",
      "y[random_start : random_start + X_y_len] y[109 : 170]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 192 61\n",
      "X.shape[0] 192\n",
      "X[random_start : random_start + X_len] X[0 : 60]\n",
      "y[random_start : random_start + X_y_len] y[0 : 61]\n",
      "X_val.shape, y_val.shape, n_seq, n_seq_val, n_seq_test, n_obs, n_feat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((40, 60, 20), (40, 1), 200, 40, 20, 60, 20)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val, y_val = get_X_y_2(X_val, y_val, X_len=n_obs, y_len=n_pred, n_sequences=n_seq_val)\n",
    "print('X_val.shape, y_val.shape, n_seq, n_seq_val, n_seq_test, n_obs, n_feat')\n",
    "X_val.shape, y_val.shape, n_seq, n_seq_val, n_seq_test, n_obs, n_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a422c04-e3ef-4daf-b870-060c559ad2bb",
   "metadata": {},
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_set('United States', split_train=0.7, split_val=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e2fa4-2cf1-4ad1-bd39-6b48cd2d478d",
   "metadata": {
    "tags": []
   },
   "source": [
    "X_train, y_train = get_X_y(X_train, y_train, X_test, y_test, X_len=n_obs, y_len=n_pred, n_seq_train=n_seq_test, X_val=X_val, y_val=y_val)\n",
    "X_train.shape, y_train.shape, n_seq, n_seq_val, n_seq_test, n_obs, n_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7826c700-4273-4cd3-b7d7-4c3cca2b3582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[297 : 357]\n",
      "y[random_start : random_start + X_y_len] y[297 : 358]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[179 : 239]\n",
      "y[random_start : random_start + X_y_len] y[179 : 240]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[11 : 71]\n",
      "y[random_start : random_start + X_y_len] y[11 : 72]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[113 : 173]\n",
      "y[random_start : random_start + X_y_len] y[113 : 174]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[39 : 99]\n",
      "y[random_start : random_start + X_y_len] y[39 : 100]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[508 : 568]\n",
      "y[random_start : random_start + X_y_len] y[508 : 569]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[262 : 322]\n",
      "y[random_start : random_start + X_y_len] y[262 : 323]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[298 : 358]\n",
      "y[random_start : random_start + X_y_len] y[298 : 359]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[254 : 314]\n",
      "y[random_start : random_start + X_y_len] y[254 : 315]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[239 : 299]\n",
      "y[random_start : random_start + X_y_len] y[239 : 300]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[72 : 132]\n",
      "y[random_start : random_start + X_y_len] y[72 : 133]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[336 : 396]\n",
      "y[random_start : random_start + X_y_len] y[336 : 397]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[170 : 230]\n",
      "y[random_start : random_start + X_y_len] y[170 : 231]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[19 : 79]\n",
      "y[random_start : random_start + X_y_len] y[19 : 80]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[546 : 606]\n",
      "y[random_start : random_start + X_y_len] y[546 : 607]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[356 : 416]\n",
      "y[random_start : random_start + X_y_len] y[356 : 417]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[449 : 509]\n",
      "y[random_start : random_start + X_y_len] y[449 : 510]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[409 : 469]\n",
      "y[random_start : random_start + X_y_len] y[409 : 470]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[333 : 393]\n",
      "y[random_start : random_start + X_y_len] y[333 : 394]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[237 : 297]\n",
      "y[random_start : random_start + X_y_len] y[237 : 298]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[415 : 475]\n",
      "y[random_start : random_start + X_y_len] y[415 : 476]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[541 : 601]\n",
      "y[random_start : random_start + X_y_len] y[541 : 602]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[197 : 257]\n",
      "y[random_start : random_start + X_y_len] y[197 : 258]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[565 : 625]\n",
      "y[random_start : random_start + X_y_len] y[565 : 626]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[410 : 470]\n",
      "y[random_start : random_start + X_y_len] y[410 : 471]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[591 : 651]\n",
      "y[random_start : random_start + X_y_len] y[591 : 652]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[229 : 289]\n",
      "y[random_start : random_start + X_y_len] y[229 : 290]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[465 : 525]\n",
      "y[random_start : random_start + X_y_len] y[465 : 526]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[199 : 259]\n",
      "y[random_start : random_start + X_y_len] y[199 : 260]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[138 : 198]\n",
      "y[random_start : random_start + X_y_len] y[138 : 199]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[130 : 190]\n",
      "y[random_start : random_start + X_y_len] y[130 : 191]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[357 : 417]\n",
      "y[random_start : random_start + X_y_len] y[357 : 418]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[237 : 297]\n",
      "y[random_start : random_start + X_y_len] y[237 : 298]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[377 : 437]\n",
      "y[random_start : random_start + X_y_len] y[377 : 438]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[280 : 340]\n",
      "y[random_start : random_start + X_y_len] y[280 : 341]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[540 : 600]\n",
      "y[random_start : random_start + X_y_len] y[540 : 601]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[426 : 486]\n",
      "y[random_start : random_start + X_y_len] y[426 : 487]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[141 : 201]\n",
      "y[random_start : random_start + X_y_len] y[141 : 202]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[498 : 558]\n",
      "y[random_start : random_start + X_y_len] y[498 : 559]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[147 : 207]\n",
      "y[random_start : random_start + X_y_len] y[147 : 208]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[273 : 333]\n",
      "y[random_start : random_start + X_y_len] y[273 : 334]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[504 : 564]\n",
      "y[random_start : random_start + X_y_len] y[504 : 565]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[177 : 237]\n",
      "y[random_start : random_start + X_y_len] y[177 : 238]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[253 : 313]\n",
      "y[random_start : random_start + X_y_len] y[253 : 314]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[202 : 262]\n",
      "y[random_start : random_start + X_y_len] y[202 : 263]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[255 : 315]\n",
      "y[random_start : random_start + X_y_len] y[255 : 316]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[97 : 157]\n",
      "y[random_start : random_start + X_y_len] y[97 : 158]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[57 : 117]\n",
      "y[random_start : random_start + X_y_len] y[57 : 118]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[604 : 664]\n",
      "y[random_start : random_start + X_y_len] y[604 : 665]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[494 : 554]\n",
      "y[random_start : random_start + X_y_len] y[494 : 555]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[373 : 433]\n",
      "y[random_start : random_start + X_y_len] y[373 : 434]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[60 : 120]\n",
      "y[random_start : random_start + X_y_len] y[60 : 121]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[167 : 227]\n",
      "y[random_start : random_start + X_y_len] y[167 : 228]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[329 : 389]\n",
      "y[random_start : random_start + X_y_len] y[329 : 390]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[299 : 359]\n",
      "y[random_start : random_start + X_y_len] y[299 : 360]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[476 : 536]\n",
      "y[random_start : random_start + X_y_len] y[476 : 537]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[555 : 615]\n",
      "y[random_start : random_start + X_y_len] y[555 : 616]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[210 : 270]\n",
      "y[random_start : random_start + X_y_len] y[210 : 271]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[42 : 102]\n",
      "y[random_start : random_start + X_y_len] y[42 : 103]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[47 : 107]\n",
      "y[random_start : random_start + X_y_len] y[47 : 108]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[197 : 257]\n",
      "y[random_start : random_start + X_y_len] y[197 : 258]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[572 : 632]\n",
      "y[random_start : random_start + X_y_len] y[572 : 633]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[579 : 639]\n",
      "y[random_start : random_start + X_y_len] y[579 : 640]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[401 : 461]\n",
      "y[random_start : random_start + X_y_len] y[401 : 462]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[148 : 208]\n",
      "y[random_start : random_start + X_y_len] y[148 : 209]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[469 : 529]\n",
      "y[random_start : random_start + X_y_len] y[469 : 530]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[318 : 378]\n",
      "y[random_start : random_start + X_y_len] y[318 : 379]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[309 : 369]\n",
      "y[random_start : random_start + X_y_len] y[309 : 370]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[387 : 447]\n",
      "y[random_start : random_start + X_y_len] y[387 : 448]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[606 : 666]\n",
      "y[random_start : random_start + X_y_len] y[606 : 667]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[554 : 614]\n",
      "y[random_start : random_start + X_y_len] y[554 : 615]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[173 : 233]\n",
      "y[random_start : random_start + X_y_len] y[173 : 234]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[3 : 63]\n",
      "y[random_start : random_start + X_y_len] y[3 : 64]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[497 : 557]\n",
      "y[random_start : random_start + X_y_len] y[497 : 558]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[193 : 253]\n",
      "y[random_start : random_start + X_y_len] y[193 : 254]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[163 : 223]\n",
      "y[random_start : random_start + X_y_len] y[163 : 224]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[560 : 620]\n",
      "y[random_start : random_start + X_y_len] y[560 : 621]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[328 : 388]\n",
      "y[random_start : random_start + X_y_len] y[328 : 389]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[255 : 315]\n",
      "y[random_start : random_start + X_y_len] y[255 : 316]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[336 : 396]\n",
      "y[random_start : random_start + X_y_len] y[336 : 397]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[182 : 242]\n",
      "y[random_start : random_start + X_y_len] y[182 : 243]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[429 : 489]\n",
      "y[random_start : random_start + X_y_len] y[429 : 490]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[322 : 382]\n",
      "y[random_start : random_start + X_y_len] y[322 : 383]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[307 : 367]\n",
      "y[random_start : random_start + X_y_len] y[307 : 368]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[559 : 619]\n",
      "y[random_start : random_start + X_y_len] y[559 : 620]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[443 : 503]\n",
      "y[random_start : random_start + X_y_len] y[443 : 504]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[257 : 317]\n",
      "y[random_start : random_start + X_y_len] y[257 : 318]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[28 : 88]\n",
      "y[random_start : random_start + X_y_len] y[28 : 89]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[51 : 111]\n",
      "y[random_start : random_start + X_y_len] y[51 : 112]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[468 : 528]\n",
      "y[random_start : random_start + X_y_len] y[468 : 529]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[478 : 538]\n",
      "y[random_start : random_start + X_y_len] y[478 : 539]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[295 : 355]\n",
      "y[random_start : random_start + X_y_len] y[295 : 356]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[314 : 374]\n",
      "y[random_start : random_start + X_y_len] y[314 : 375]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[396 : 456]\n",
      "y[random_start : random_start + X_y_len] y[396 : 457]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[571 : 631]\n",
      "y[random_start : random_start + X_y_len] y[571 : 632]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[19 : 79]\n",
      "y[random_start : random_start + X_y_len] y[19 : 80]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[127 : 187]\n",
      "y[random_start : random_start + X_y_len] y[127 : 188]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[415 : 475]\n",
      "y[random_start : random_start + X_y_len] y[415 : 476]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[258 : 318]\n",
      "y[random_start : random_start + X_y_len] y[258 : 319]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[29 : 89]\n",
      "y[random_start : random_start + X_y_len] y[29 : 90]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[224 : 284]\n",
      "y[random_start : random_start + X_y_len] y[224 : 285]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[345 : 405]\n",
      "y[random_start : random_start + X_y_len] y[345 : 406]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[451 : 511]\n",
      "y[random_start : random_start + X_y_len] y[451 : 512]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[334 : 394]\n",
      "y[random_start : random_start + X_y_len] y[334 : 395]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[445 : 505]\n",
      "y[random_start : random_start + X_y_len] y[445 : 506]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[96 : 156]\n",
      "y[random_start : random_start + X_y_len] y[96 : 157]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[459 : 519]\n",
      "y[random_start : random_start + X_y_len] y[459 : 520]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[414 : 474]\n",
      "y[random_start : random_start + X_y_len] y[414 : 475]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[469 : 529]\n",
      "y[random_start : random_start + X_y_len] y[469 : 530]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[423 : 483]\n",
      "y[random_start : random_start + X_y_len] y[423 : 484]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[61 : 121]\n",
      "y[random_start : random_start + X_y_len] y[61 : 122]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[154 : 214]\n",
      "y[random_start : random_start + X_y_len] y[154 : 215]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[328 : 388]\n",
      "y[random_start : random_start + X_y_len] y[328 : 389]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[55 : 115]\n",
      "y[random_start : random_start + X_y_len] y[55 : 116]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[332 : 392]\n",
      "y[random_start : random_start + X_y_len] y[332 : 393]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[124 : 184]\n",
      "y[random_start : random_start + X_y_len] y[124 : 185]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[311 : 371]\n",
      "y[random_start : random_start + X_y_len] y[311 : 372]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[332 : 392]\n",
      "y[random_start : random_start + X_y_len] y[332 : 393]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[389 : 449]\n",
      "y[random_start : random_start + X_y_len] y[389 : 450]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[75 : 135]\n",
      "y[random_start : random_start + X_y_len] y[75 : 136]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[130 : 190]\n",
      "y[random_start : random_start + X_y_len] y[130 : 191]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[389 : 449]\n",
      "y[random_start : random_start + X_y_len] y[389 : 450]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[78 : 138]\n",
      "y[random_start : random_start + X_y_len] y[78 : 139]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[590 : 650]\n",
      "y[random_start : random_start + X_y_len] y[590 : 651]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[252 : 312]\n",
      "y[random_start : random_start + X_y_len] y[252 : 313]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[202 : 262]\n",
      "y[random_start : random_start + X_y_len] y[202 : 263]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[59 : 119]\n",
      "y[random_start : random_start + X_y_len] y[59 : 120]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[86 : 146]\n",
      "y[random_start : random_start + X_y_len] y[86 : 147]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[511 : 571]\n",
      "y[random_start : random_start + X_y_len] y[511 : 572]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[231 : 291]\n",
      "y[random_start : random_start + X_y_len] y[231 : 292]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[97 : 157]\n",
      "y[random_start : random_start + X_y_len] y[97 : 158]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[373 : 433]\n",
      "y[random_start : random_start + X_y_len] y[373 : 434]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[28 : 88]\n",
      "y[random_start : random_start + X_y_len] y[28 : 89]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[325 : 385]\n",
      "y[random_start : random_start + X_y_len] y[325 : 386]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[42 : 102]\n",
      "y[random_start : random_start + X_y_len] y[42 : 103]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[289 : 349]\n",
      "y[random_start : random_start + X_y_len] y[289 : 350]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[290 : 350]\n",
      "y[random_start : random_start + X_y_len] y[290 : 351]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[375 : 435]\n",
      "y[random_start : random_start + X_y_len] y[375 : 436]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[205 : 265]\n",
      "y[random_start : random_start + X_y_len] y[205 : 266]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[382 : 442]\n",
      "y[random_start : random_start + X_y_len] y[382 : 443]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[474 : 534]\n",
      "y[random_start : random_start + X_y_len] y[474 : 535]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[114 : 174]\n",
      "y[random_start : random_start + X_y_len] y[114 : 175]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[599 : 659]\n",
      "y[random_start : random_start + X_y_len] y[599 : 660]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[419 : 479]\n",
      "y[random_start : random_start + X_y_len] y[419 : 480]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[154 : 214]\n",
      "y[random_start : random_start + X_y_len] y[154 : 215]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[398 : 458]\n",
      "y[random_start : random_start + X_y_len] y[398 : 459]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[313 : 373]\n",
      "y[random_start : random_start + X_y_len] y[313 : 374]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[340 : 400]\n",
      "y[random_start : random_start + X_y_len] y[340 : 401]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[449 : 509]\n",
      "y[random_start : random_start + X_y_len] y[449 : 510]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[225 : 285]\n",
      "y[random_start : random_start + X_y_len] y[225 : 286]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[532 : 592]\n",
      "y[random_start : random_start + X_y_len] y[532 : 593]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[361 : 421]\n",
      "y[random_start : random_start + X_y_len] y[361 : 422]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[294 : 354]\n",
      "y[random_start : random_start + X_y_len] y[294 : 355]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[96 : 156]\n",
      "y[random_start : random_start + X_y_len] y[96 : 157]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[547 : 607]\n",
      "y[random_start : random_start + X_y_len] y[547 : 608]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[207 : 267]\n",
      "y[random_start : random_start + X_y_len] y[207 : 268]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[363 : 423]\n",
      "y[random_start : random_start + X_y_len] y[363 : 424]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[275 : 335]\n",
      "y[random_start : random_start + X_y_len] y[275 : 336]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[19 : 79]\n",
      "y[random_start : random_start + X_y_len] y[19 : 80]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[247 : 307]\n",
      "y[random_start : random_start + X_y_len] y[247 : 308]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[248 : 308]\n",
      "y[random_start : random_start + X_y_len] y[248 : 309]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[25 : 85]\n",
      "y[random_start : random_start + X_y_len] y[25 : 86]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[250 : 310]\n",
      "y[random_start : random_start + X_y_len] y[250 : 311]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[576 : 636]\n",
      "y[random_start : random_start + X_y_len] y[576 : 637]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[86 : 146]\n",
      "y[random_start : random_start + X_y_len] y[86 : 147]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[75 : 135]\n",
      "y[random_start : random_start + X_y_len] y[75 : 136]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[45 : 105]\n",
      "y[random_start : random_start + X_y_len] y[45 : 106]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[164 : 224]\n",
      "y[random_start : random_start + X_y_len] y[164 : 225]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[409 : 469]\n",
      "y[random_start : random_start + X_y_len] y[409 : 470]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[187 : 247]\n",
      "y[random_start : random_start + X_y_len] y[187 : 248]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[239 : 299]\n",
      "y[random_start : random_start + X_y_len] y[239 : 300]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[251 : 311]\n",
      "y[random_start : random_start + X_y_len] y[251 : 312]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[444 : 504]\n",
      "y[random_start : random_start + X_y_len] y[444 : 505]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[419 : 479]\n",
      "y[random_start : random_start + X_y_len] y[419 : 480]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[105 : 165]\n",
      "y[random_start : random_start + X_y_len] y[105 : 166]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[344 : 404]\n",
      "y[random_start : random_start + X_y_len] y[344 : 405]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[284 : 344]\n",
      "y[random_start : random_start + X_y_len] y[284 : 345]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[109 : 169]\n",
      "y[random_start : random_start + X_y_len] y[109 : 170]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[491 : 551]\n",
      "y[random_start : random_start + X_y_len] y[491 : 552]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[33 : 93]\n",
      "y[random_start : random_start + X_y_len] y[33 : 94]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[202 : 262]\n",
      "y[random_start : random_start + X_y_len] y[202 : 263]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[102 : 162]\n",
      "y[random_start : random_start + X_y_len] y[102 : 163]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[235 : 295]\n",
      "y[random_start : random_start + X_y_len] y[235 : 296]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[526 : 586]\n",
      "y[random_start : random_start + X_y_len] y[526 : 587]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[177 : 237]\n",
      "y[random_start : random_start + X_y_len] y[177 : 238]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[85 : 145]\n",
      "y[random_start : random_start + X_y_len] y[85 : 146]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[433 : 493]\n",
      "y[random_start : random_start + X_y_len] y[433 : 494]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[146 : 206]\n",
      "y[random_start : random_start + X_y_len] y[146 : 207]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[356 : 416]\n",
      "y[random_start : random_start + X_y_len] y[356 : 417]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[80 : 140]\n",
      "y[random_start : random_start + X_y_len] y[80 : 141]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[128 : 188]\n",
      "y[random_start : random_start + X_y_len] y[128 : 189]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[282 : 342]\n",
      "y[random_start : random_start + X_y_len] y[282 : 343]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[88 : 148]\n",
      "y[random_start : random_start + X_y_len] y[88 : 149]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[472 : 532]\n",
      "y[random_start : random_start + X_y_len] y[472 : 533]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[440 : 500]\n",
      "y[random_start : random_start + X_y_len] y[440 : 501]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[51 : 111]\n",
      "y[random_start : random_start + X_y_len] y[51 : 112]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[247 : 307]\n",
      "y[random_start : random_start + X_y_len] y[247 : 308]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[72 : 132]\n",
      "y[random_start : random_start + X_y_len] y[72 : 133]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[567 : 627]\n",
      "y[random_start : random_start + X_y_len] y[567 : 628]\n",
      "_len + y_len 60 1\n",
      "X.shape[0] >= X_y_len 672 61\n",
      "X.shape[0] 672\n",
      "X[random_start : random_start + X_len] X[355 : 415]\n",
      "y[random_start : random_start + X_y_len] y[355 : 416]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((200, 60, 20), (200, 1), 200, 60, 20)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = get_X_y_2(X_train, y_train, X_len=n_obs, y_len=n_pred, n_sequences=n_seq)\n",
    "X_train.shape, y_train.shape, n_seq, n_obs, n_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2a397-4b64-4358-8355-2a243e990afa",
   "metadata": {
    "tags": []
   },
   "source": [
    "X_val, y_val = get_X_y_2(X_val, y_val, X_len=n_obs, y_len=n_pred, n_sequences=n_seq_val)\n",
    "X_val.shape, y_val.shape, n_seq_val, n_obs, n_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec27cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.ndim(X_train), np.ndim(y_train), np.ndim(X_val), np.ndim(y_val), np.ndim(X_test), np.ndim(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "661159e6-4eb3-48cc-b11d-fff40fb81a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alberto train set\n",
    "# 3. Training\n",
    "def train_rnn_model(model, patience=2, epochs=200):\n",
    "    es = EarlyStopping(monitor = 'val_loss',\n",
    "                    patience = patience,\n",
    "                    verbose = 1,\n",
    "                    restore_best_weights = True)\n",
    "    # The fit\n",
    "    history =  model.fit(X_train, y_train, \n",
    "            validation_split=0.1, # Auto split for validation data\n",
    "                ## validation_data = (X_val, y_val), # To be created manually if needed\n",
    "            batch_size = 16,\n",
    "            epochs = epochs,\n",
    "            callbacks = [es],\n",
    "            verbose=1)\n",
    "    return history\n",
    "\n",
    "\n",
    "# print(type(overfit_es), overfit_es)\n",
    "# if overfit_es:\n",
    "#     print(\"early stopping\")\n",
    "#     history = train_rnn_model(patience=overfit_es)\n",
    "# else:\n",
    "# print(\"No early stopping\")\n",
    "# history = train_rnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe229ed-38be-485e-9314-5a3c04da8847",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### How to split sequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49128bf-f5e8-4319-8635-fa1f63c29ceb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- randomly or\n",
    "\n",
    "- manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad867c99-9dd9-4dc5-9cda-de741bf57ca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **train_rnn_model(model, patience=2, epochs=200):**\n",
    "\n",
    "function to generates an entire dataset of multiple subsamples suitable for RNN, that is, $(X, y)$ of shape:\n",
    "\n",
    "```python\n",
    "X.shape = (n_sequences, length, n_features)\n",
    "y.shape = (n_sequences, )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ece011-197d-439e-b405-ee2370c9773d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model #4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3dc24c32-f615-4696-b4e0-01e7d7281ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Training\n",
    "def train_rnn_model(model, patience=20, epochs=200):\n",
    "    \"\"\" function that train a RNN model with hyperparameters:\n",
    "    - patience by default 2 to early stop\n",
    "    - epochs by default 200 to train over several epochs\n",
    "    - valisation data by default (X_val, y_val)=(0, 0) in case of auto split\n",
    "    \"\"\"\n",
    "    es = EarlyStopping(monitor = 'val_loss',\n",
    "                    patience = patience,\n",
    "                    verbose = 0,\n",
    "                    restore_best_weights = True)\n",
    "    # The fit\n",
    "    history =  model.fit(X_train,\n",
    "            y_train, \n",
    "             # Auto split for validation data\n",
    "            # [print(f'validation_data=(X_val, y_val),') if (X_val!=0 or y_val!=0) else print(f'validation_split=0.1,')],\n",
    "            validation_data=(X_val, y_val),\n",
    "            batch_size = 16,\n",
    "            epochs = epochs,\n",
    "            callbacks = [es],\n",
    "            verbose=1)\n",
    "    return history\n",
    "\n",
    "\n",
    "# print(type(overfit_es), overfit_es)\n",
    "# if overfit_es:\n",
    "#     print(\"early stopping\")\n",
    "#     history = train_rnn_model(patience=overfit_es)\n",
    "# else:\n",
    "# print(\"No early stopping\")\n",
    "# history = train_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f844bf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 60, 20)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a7bd6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,501\n",
      "Trainable params: 3,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Alberto model #4 test \n",
    "# Normalization layer not necessary as X_train already train\n",
    "normalizer = Normalization()  # Instantiate a \"normalizer\" layer\n",
    "normalizer.adapt(X_train) # \"Fit\" it on the train set\n",
    "# 1. The Architecture\n",
    "\"\"\"   - 3rd model layers architecture (simple -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "> LSTM\n",
    "\"\"\"\n",
    "rnn_model_4 = Sequential()\n",
    "# rnn_model_4.add(normalizer) # Using the Normalization layer to standardize the datapoints during the forward pass\n",
    "# Input len(train) (input_shape=(?,?))\n",
    "rnn_model_4.add(LSTM(units=20, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))  ## , input_shape=(?,?))) without a Normalizer layer\n",
    "# output return sequences = True\n",
    "rnn_model_4.add(Dense(10, activation = 'relu')) ## add 1 or more 'relu' layers\n",
    "# Output 10 only, no more RNN just dropout()\n",
    "# rnn_model_3.add(layers.Dropout(0.3)) ## if RNN model over-fit\n",
    "rnn_model_4.add(Dense(n_pred, activation = 'linear'))\n",
    "#ValueError: Input 0 of layer \"lstm_1\" is incompatible with the layer:\n",
    "#     >>> expected ndim=3, found ndim=2. Full shape received: (None, 20)#\n",
    "# 2. Compiling with 'rmsprop' rather than 'adam' (recommended)\n",
    "optimizer = RMSprop(\n",
    "                learning_rate=0.001,\n",
    "                rho=0.9,\n",
    "                momentum=0.0,\n",
    "                epsilon=1e-07,\n",
    "                centered=False\n",
    "            )\n",
    "rnn_model_4.compile(loss='mse',\n",
    "              optimizer= optimizer, # optimizer='rmsprop'    <- adapt learning rate\n",
    "                 metrics='mape')  # Recommended optimizer for RNNs\n",
    "rnn_model_4.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8cd997f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 [==============================] - 6s 159ms/step - loss: 5716969472.0000 - mape: 99.5064 - val_loss: 18147563520.0000 - val_mape: 98.7144\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 4142856960.0000 - mape: 77.4232 - val_loss: 13954816000.0000 - val_mape: 86.3879\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 1s 85ms/step - loss: 2946388736.0000 - mape: 60.4023 - val_loss: 14262009856.0000 - val_mape: 87.3235\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 1s 97ms/step - loss: 2742668288.0000 - mape: 59.5244 - val_loss: 12339607552.0000 - val_mape: 81.0917\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 1689369600.0000 - mape: 60.0391 - val_loss: 9149872128.0000 - val_mape: 69.1997\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 1s 89ms/step - loss: 1538672768.0000 - mape: 59.7552 - val_loss: 10018846720.0000 - val_mape: 72.7777\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 2550003200.0000 - mape: 92.4066 - val_loss: 2815456768.0000 - val_mape: 35.0564\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 5978347520.0000 - mape: 155.1450 - val_loss: 4009866752.0000 - val_mape: 43.4089\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 3546260480.0000 - mape: 90.2332 - val_loss: 12742950912.0000 - val_mape: 82.4225\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 1s 83ms/step - loss: 1838069888.0000 - mape: 54.3139 - val_loss: 9075938304.0000 - val_mape: 69.1584\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Training\n",
    "history = train_rnn_model(model=rnn_model_4, epochs=200, patience=3)\n",
    "plt.plot(history.history['mape'])\n",
    "plt.plot(history.history['val_mape'])\n",
    "plt.show();\n",
    "\n",
    "# 4. Evaluating\n",
    "# The prediction (one per sequence/city)\n",
    "# y_pred = rnn_model.predict(X_test) \n",
    "# print(y_pred.shape)\n",
    "# Distribution of the predictions\n",
    "# pd.DataFrame(y_pred).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f87f4-a522-43df-9486-ac6e4930ae60",
   "metadata": {},
   "source": [
    "# Alberto model #4 End Of the Road..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8884eb78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Training\n",
    "def train_rnn_model(model, patience=20, epochs=200):\n",
    "    es = EarlyStopping(monitor = 'val_loss',\n",
    "                    patience = patience,\n",
    "                    verbose = 0,\n",
    "                    restore_best_weights = True)\n",
    "    # The fit\n",
    "    history =  model.fit(X_train,\n",
    "            y_train, \n",
    "            validation_split=0.1, # Auto split for validation data\n",
    "                ## validation_data = (X_val, y_val), # To be created manually if needed\n",
    "            batch_size = 16,\n",
    "            epochs = epochs,\n",
    "            callbacks = [es],\n",
    "            verbose=1)\n",
    "    return history\n",
    "\n",
    "\n",
    "# print(type(overfit_es), overfit_es)\n",
    "# if overfit_es:\n",
    "#     print(\"early stopping\")\n",
    "#     history = train_rnn_model(patience=overfit_es)\n",
    "# else:\n",
    "# print(\"No early stopping\")\n",
    "# history = train_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce50f5c4-faa0-4355-a1fd-a28b28062623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. The Normalization Layer\n",
    "# normalizer = Normalization()  # Instantiate a \"normalizer\" layer\n",
    "# normalizer.adapt(X_train) # \"Fit\" it on the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a652e-f059-4adf-bf05-62b7120a24d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RNN model #3 architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50d57380-7866-4ec5-8e40-b86653234646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Architecture\n",
    "\"\"\"   - 3rd model layers architecture (simple -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "> LSTM\n",
    "\"\"\"\n",
    "rnn_model_3 = Sequential()\n",
    "rnn_model_3.add(normalizer) # Using the Normalization layer to standardize the datapoints during the forward pass\n",
    "# Input len(train) (input_shape=(?,?))\n",
    "rnn_model_3.add(LSTM(units=30, activation='tanh'))  ## , input_shape=(?,?))) without a Normalizer layer\n",
    "# output return sequences = True\n",
    "rnn_model_3.add(Dense(10, activation = 'relu')) ## add 1 or more 'relu' layers\n",
    "# Output 10 only, no more RNN just dropout()\n",
    "# rnn_model_3.add(layers.Dropout(0.3)) ## if RNN model over-fit\n",
    "rnn_model_3.add(Dense(n_pred, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e901218-eb1c-4d85-b40e-9beda6c3c548",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model #1 evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "db1267f1-8a86-4f8b-82f5-01478bc0d350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    55163.554688\n",
       "dtype: float32"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Evaluating\n",
    "# The prediction (one per sequence/city)\n",
    "y_pred = rnn_model_4.predict(X_test) \n",
    "print(y_pred.shape)\n",
    "# Distribution of the predictions\n",
    "pd.DataFrame(y_pred).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c615d0-d83c-4b7d-b076-b914179fb0ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time Series Forecasting with model #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbe63f-114d-4717-a404-0aa7b96de1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile model #3 with 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9524eb0a-0117-4006-af85-9f8235e96cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_5 (Normalizat  (None, None, 20)         41        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 30)                6120      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,482\n",
      "Trainable params: 6,441\n",
      "Non-trainable params: 41\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. Compiling with 'rmsprop' rather than 'adam' (recommended)\n",
    "optimizer = RMSprop(\n",
    "                learning_rate=0.001,\n",
    "                rho=0.9,\n",
    "                momentum=0.0,\n",
    "                epsilon=1e-07,\n",
    "                centered=False\n",
    "            )\n",
    "rnn_model_3.compile(loss='mse',\n",
    "              optimizer= optimizer, # optimizer='rmsprop'    <- adapt learning rate\n",
    "                 metrics='mape')  # Recommended optimizer for RNNs\n",
    "rnn_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a685f57-01a6-4405-8b38-0cc3c7fa5489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,501\n",
      "Trainable params: 3,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739df8e1-5a54-4634-a074-e644a6a796a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "571254c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 9s 225ms/step - loss: 5849038848.0000 - mape: 99.9996 - val_loss: 4782161920.0000 - val_mape: 99.9993\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 5848934912.0000 - mape: 99.9987 - val_loss: 4782081536.0000 - val_mape: 99.9985\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5848840704.0000 - mape: 99.9978 - val_loss: 4782003712.0000 - val_mape: 99.9977\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 5848742912.0000 - mape: 99.9969 - val_loss: 4781923328.0000 - val_mape: 99.9969\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 5848645632.0000 - mape: 99.9960 - val_loss: 4781848064.0000 - val_mape: 99.9958\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5848547840.0000 - mape: 99.9947 - val_loss: 4781759488.0000 - val_mape: 99.9943\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5848437248.0000 - mape: 99.9931 - val_loss: 4781659648.0000 - val_mape: 99.9924\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5848318976.0000 - mape: 99.9913 - val_loss: 4781552640.0000 - val_mape: 99.9905\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 5848194048.0000 - mape: 99.9896 - val_loss: 4781449216.0000 - val_mape: 99.9886\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5848062976.0000 - mape: 99.9878 - val_loss: 4781307392.0000 - val_mape: 99.9864\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 5847880192.0000 - mape: 99.9855 - val_loss: 4781154304.0000 - val_mape: 99.9838\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5847694848.0000 - mape: 99.9829 - val_loss: 4780967936.0000 - val_mape: 99.9797\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 5847491584.0000 - mape: 99.9794 - val_loss: 4780731392.0000 - val_mape: 99.9728\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 5847290368.0000 - mape: 99.9755 - val_loss: 4780551168.0000 - val_mape: 99.9685\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 5847084032.0000 - mape: 99.9685 - val_loss: 4780368384.0000 - val_mape: 99.9639\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 5846872576.0000 - mape: 99.9633 - val_loss: 4780186624.0000 - val_mape: 99.9602\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 5846658560.0000 - mape: 99.9586 - val_loss: 4779989504.0000 - val_mape: 99.9565\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5846437888.0000 - mape: 99.9541 - val_loss: 4779797504.0000 - val_mape: 99.9527\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5846217728.0000 - mape: 99.9500 - val_loss: 4779603456.0000 - val_mape: 99.9489\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 5845984768.0000 - mape: 99.9457 - val_loss: 4779403264.0000 - val_mape: 99.9452\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 5845764096.0000 - mape: 99.9418 - val_loss: 4779207680.0000 - val_mape: 99.9413\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 5845538816.0000 - mape: 99.9373 - val_loss: 4779013120.0000 - val_mape: 99.9375\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5845313024.0000 - mape: 99.9335 - val_loss: 4778802688.0000 - val_mape: 99.9335\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5845074944.0000 - mape: 99.9290 - val_loss: 4778593792.0000 - val_mape: 99.9294\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 5844834304.0000 - mape: 99.9247 - val_loss: 4778379264.0000 - val_mape: 99.9252\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 5844587008.0000 - mape: 99.9206 - val_loss: 4778162176.0000 - val_mape: 99.9210\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 5844335616.0000 - mape: 99.9162 - val_loss: 4777931776.0000 - val_mape: 99.9166\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 5844070912.0000 - mape: 99.9116 - val_loss: 4777702400.0000 - val_mape: 99.9122\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5843811328.0000 - mape: 99.9069 - val_loss: 4777470976.0000 - val_mape: 99.9077\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 5843545088.0000 - mape: 99.9021 - val_loss: 4777225728.0000 - val_mape: 99.9029\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5843262976.0000 - mape: 99.8975 - val_loss: 4776974336.0000 - val_mape: 99.8981\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 5842978304.0000 - mape: 99.8923 - val_loss: 4776729600.0000 - val_mape: 99.8933\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5842695168.0000 - mape: 99.8873 - val_loss: 4776465408.0000 - val_mape: 99.8882\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5842397696.0000 - mape: 99.8820 - val_loss: 4776210432.0000 - val_mape: 99.8833\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 5842101248.0000 - mape: 99.8770 - val_loss: 4775947264.0000 - val_mape: 99.8782\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5841800192.0000 - mape: 99.8710 - val_loss: 4775678464.0000 - val_mape: 99.8730\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 5841492480.0000 - mape: 99.8657 - val_loss: 4775404544.0000 - val_mape: 99.8677\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5841174016.0000 - mape: 99.8607 - val_loss: 4775115776.0000 - val_mape: 99.8621\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5840846336.0000 - mape: 99.8543 - val_loss: 4774825984.0000 - val_mape: 99.8566\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5840511488.0000 - mape: 99.8489 - val_loss: 4774521344.0000 - val_mape: 99.8507\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5840170496.0000 - mape: 99.8424 - val_loss: 4774236160.0000 - val_mape: 99.8451\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5839838720.0000 - mape: 99.8370 - val_loss: 4773933056.0000 - val_mape: 99.8393\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 5839492608.0000 - mape: 99.8309 - val_loss: 4773626368.0000 - val_mape: 99.8334\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 5839137280.0000 - mape: 99.8248 - val_loss: 4773300224.0000 - val_mape: 99.8270\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5838772224.0000 - mape: 99.8178 - val_loss: 4772986880.0000 - val_mape: 99.8210\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 5838409216.0000 - mape: 99.8117 - val_loss: 4772660224.0000 - val_mape: 99.8147\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5838036480.0000 - mape: 99.8052 - val_loss: 4772331520.0000 - val_mape: 99.8083\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5837662208.0000 - mape: 99.7981 - val_loss: 4771992064.0000 - val_mape: 99.8018\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 1s 104ms/step - loss: 5837271552.0000 - mape: 99.7915 - val_loss: 4771642880.0000 - val_mape: 99.7950\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 5836876800.0000 - mape: 99.7848 - val_loss: 4771304960.0000 - val_mape: 99.7885\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5836485120.0000 - mape: 99.7778 - val_loss: 4770952192.0000 - val_mape: 99.7817\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 5836081152.0000 - mape: 99.7703 - val_loss: 4770593792.0000 - val_mape: 99.7747\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5835675136.0000 - mape: 99.7629 - val_loss: 4770239488.0000 - val_mape: 99.7679\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 5835262976.0000 - mape: 99.7560 - val_loss: 4769873920.0000 - val_mape: 99.7608\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 5834849280.0000 - mape: 99.7489 - val_loss: 4769503744.0000 - val_mape: 99.7536\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 5834423808.0000 - mape: 99.7412 - val_loss: 4769120256.0000 - val_mape: 99.7462\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 5833986560.0000 - mape: 99.7334 - val_loss: 4768735744.0000 - val_mape: 99.7388\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 5833546240.0000 - mape: 99.7259 - val_loss: 4768342528.0000 - val_mape: 99.7312\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 2s 123ms/step - loss: 5833102848.0000 - mape: 99.7178 - val_loss: 4767955968.0000 - val_mape: 99.7237\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 5832659456.0000 - mape: 99.7102 - val_loss: 4767564800.0000 - val_mape: 99.7162\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 5832209920.0000 - mape: 99.7024 - val_loss: 4767167488.0000 - val_mape: 99.7085\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 5831752704.0000 - mape: 99.6937 - val_loss: 4766749184.0000 - val_mape: 99.7004\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 5831272448.0000 - mape: 99.6862 - val_loss: 4766330880.0000 - val_mape: 99.6923\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 2s 166ms/step - loss: 5830797824.0000 - mape: 99.6771 - val_loss: 4765917696.0000 - val_mape: 99.6843\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 2s 138ms/step - loss: 5830321664.0000 - mape: 99.6694 - val_loss: 4765485568.0000 - val_mape: 99.6759\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 5829833728.0000 - mape: 99.6605 - val_loss: 4765058048.0000 - val_mape: 99.6676\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 5829347328.0000 - mape: 99.6510 - val_loss: 4764630016.0000 - val_mape: 99.6594\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 5828850688.0000 - mape: 99.6430 - val_loss: 4764191232.0000 - val_mape: 99.6509\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 1s 124ms/step - loss: 5828349952.0000 - mape: 99.6346 - val_loss: 4763745792.0000 - val_mape: 99.6423\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 1s 118ms/step - loss: 5827837440.0000 - mape: 99.6258 - val_loss: 4763293184.0000 - val_mape: 99.6335\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 5827322368.0000 - mape: 99.6165 - val_loss: 4762835968.0000 - val_mape: 99.6246\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 5826806272.0000 - mape: 99.6062 - val_loss: 4762387456.0000 - val_mape: 99.6160\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 5826287104.0000 - mape: 99.5973 - val_loss: 4761903104.0000 - val_mape: 99.6066\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 5825745408.0000 - mape: 99.5876 - val_loss: 4761446400.0000 - val_mape: 99.5977\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5825211904.0000 - mape: 99.5791 - val_loss: 4760954368.0000 - val_mape: 99.5882\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5824665088.0000 - mape: 99.5685 - val_loss: 4760488960.0000 - val_mape: 99.5792\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5824119296.0000 - mape: 99.5596 - val_loss: 4759991296.0000 - val_mape: 99.5696\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5823559168.0000 - mape: 99.5497 - val_loss: 4759493120.0000 - val_mape: 99.5599\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5822989824.0000 - mape: 99.5397 - val_loss: 4759006720.0000 - val_mape: 99.5505\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5822432768.0000 - mape: 99.5297 - val_loss: 4758499328.0000 - val_mape: 99.5407\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5821850624.0000 - mape: 99.5197 - val_loss: 4757986304.0000 - val_mape: 99.5307\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 5821270016.0000 - mape: 99.5088 - val_loss: 4757483520.0000 - val_mape: 99.5210\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 5820692480.0000 - mape: 99.4989 - val_loss: 4756972544.0000 - val_mape: 99.5111\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 5820100096.0000 - mape: 99.4886 - val_loss: 4756426752.0000 - val_mape: 99.5005\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5819487232.0000 - mape: 99.4781 - val_loss: 4755901440.0000 - val_mape: 99.4904\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5818889728.0000 - mape: 99.4668 - val_loss: 4755375104.0000 - val_mape: 99.4801\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 5818286080.0000 - mape: 99.4556 - val_loss: 4754833408.0000 - val_mape: 99.4697\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5817664512.0000 - mape: 99.4454 - val_loss: 4754297856.0000 - val_mape: 99.4593\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5817053696.0000 - mape: 99.4338 - val_loss: 4753742848.0000 - val_mape: 99.4485\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5816422912.0000 - mape: 99.4230 - val_loss: 4753173504.0000 - val_mape: 99.4375\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5815778816.0000 - mape: 99.4114 - val_loss: 4752613376.0000 - val_mape: 99.4266\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 5815137280.0000 - mape: 99.4005 - val_loss: 4752045056.0000 - val_mape: 99.4156\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 5814490624.0000 - mape: 99.3885 - val_loss: 4751489024.0000 - val_mape: 99.4048\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 5813853184.0000 - mape: 99.3777 - val_loss: 4750913536.0000 - val_mape: 99.3937\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 5813192704.0000 - mape: 99.3657 - val_loss: 4750329344.0000 - val_mape: 99.3823\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 5812527104.0000 - mape: 99.3548 - val_loss: 4749751296.0000 - val_mape: 99.3711\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5811868160.0000 - mape: 99.3419 - val_loss: 4749166592.0000 - val_mape: 99.3598\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 5811195392.0000 - mape: 99.3312 - val_loss: 4748583936.0000 - val_mape: 99.3485\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5810524672.0000 - mape: 99.3195 - val_loss: 4747974144.0000 - val_mape: 99.3367\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 5809836544.0000 - mape: 99.3070 - val_loss: 4747363840.0000 - val_mape: 99.3248\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 5809140736.0000 - mape: 99.2946 - val_loss: 4746742784.0000 - val_mape: 99.3128\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 5808427520.0000 - mape: 99.2821 - val_loss: 4746112512.0000 - val_mape: 99.3006\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5807724544.0000 - mape: 99.2687 - val_loss: 4745500160.0000 - val_mape: 99.2887\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 5807023104.0000 - mape: 99.2570 - val_loss: 4744901632.0000 - val_mape: 99.2770\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 5806320128.0000 - mape: 99.2456 - val_loss: 4744250880.0000 - val_mape: 99.2644\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5805596160.0000 - mape: 99.2311 - val_loss: 4743626240.0000 - val_mape: 99.2523\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5804872704.0000 - mape: 99.2197 - val_loss: 4742964736.0000 - val_mape: 99.2395\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 1s 100ms/step - loss: 5804126208.0000 - mape: 99.2060 - val_loss: 4742310912.0000 - val_mape: 99.2268\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 1s 100ms/step - loss: 5803379712.0000 - mape: 99.1934 - val_loss: 4741664256.0000 - val_mape: 99.2142\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 5802644992.0000 - mape: 99.1794 - val_loss: 4741024768.0000 - val_mape: 99.2018\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5801906688.0000 - mape: 99.1658 - val_loss: 4740340736.0000 - val_mape: 99.1885\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 5801141248.0000 - mape: 99.1520 - val_loss: 4739697664.0000 - val_mape: 99.1760\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 5800398848.0000 - mape: 99.1395 - val_loss: 4739036160.0000 - val_mape: 99.1632\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 5799629312.0000 - mape: 99.1265 - val_loss: 4738337792.0000 - val_mape: 99.1496\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 5798845952.0000 - mape: 99.1122 - val_loss: 4737645568.0000 - val_mape: 99.1362\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 5798056448.0000 - mape: 99.0985 - val_loss: 4736969216.0000 - val_mape: 99.1230\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5797276160.0000 - mape: 99.0856 - val_loss: 4736252928.0000 - val_mape: 99.1091\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5796469760.0000 - mape: 99.0706 - val_loss: 4735538176.0000 - val_mape: 99.0952\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 5795671552.0000 - mape: 99.0559 - val_loss: 4734860800.0000 - val_mape: 99.0821\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 5794884096.0000 - mape: 99.0423 - val_loss: 4734153728.0000 - val_mape: 99.0683\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 1s 97ms/step - loss: 5794081792.0000 - mape: 99.0271 - val_loss: 4733445120.0000 - val_mape: 99.0545\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5793269760.0000 - mape: 99.0127 - val_loss: 4732731904.0000 - val_mape: 99.0407\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 5792455680.0000 - mape: 98.9981 - val_loss: 4732020736.0000 - val_mape: 99.0269\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 5791624192.0000 - mape: 98.9853 - val_loss: 4731266048.0000 - val_mape: 99.0122\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 5790775296.0000 - mape: 98.9701 - val_loss: 4730525184.0000 - val_mape: 98.9978\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 5789938688.0000 - mape: 98.9536 - val_loss: 4729814016.0000 - val_mape: 98.9840\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5789115904.0000 - mape: 98.9397 - val_loss: 4729047040.0000 - val_mape: 98.9690\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5788250112.0000 - mape: 98.9250 - val_loss: 4728324096.0000 - val_mape: 98.9550\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5787409920.0000 - mape: 98.9095 - val_loss: 4727539712.0000 - val_mape: 98.9397\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 5786531328.0000 - mape: 98.8949 - val_loss: 4726770688.0000 - val_mape: 98.9248\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 5785659392.0000 - mape: 98.8790 - val_loss: 4726037504.0000 - val_mape: 98.9105\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5784814080.0000 - mape: 98.8639 - val_loss: 4725282304.0000 - val_mape: 98.8958\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5783939584.0000 - mape: 98.8478 - val_loss: 4724465664.0000 - val_mape: 98.8799\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5783035904.0000 - mape: 98.8320 - val_loss: 4723703296.0000 - val_mape: 98.8651\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 5782163968.0000 - mape: 98.8154 - val_loss: 4722943488.0000 - val_mape: 98.8503\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5781280256.0000 - mape: 98.8008 - val_loss: 4722135552.0000 - val_mape: 98.8345\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5780372992.0000 - mape: 98.7846 - val_loss: 4721370112.0000 - val_mape: 98.8197\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5779476992.0000 - mape: 98.7689 - val_loss: 4720534528.0000 - val_mape: 98.8034\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5778541568.0000 - mape: 98.7524 - val_loss: 4719732736.0000 - val_mape: 98.7878\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5777623552.0000 - mape: 98.7362 - val_loss: 4718944768.0000 - val_mape: 98.7724\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 1s 97ms/step - loss: 5776716800.0000 - mape: 98.7187 - val_loss: 4718119936.0000 - val_mape: 98.7563\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5775770624.0000 - mape: 98.7031 - val_loss: 4717294592.0000 - val_mape: 98.7403\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5774833664.0000 - mape: 98.6857 - val_loss: 4716464640.0000 - val_mape: 98.7241\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5773891072.0000 - mape: 98.6685 - val_loss: 4715622912.0000 - val_mape: 98.7077\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5772938240.0000 - mape: 98.6519 - val_loss: 4714793472.0000 - val_mape: 98.6915\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5771991552.0000 - mape: 98.6355 - val_loss: 4713960448.0000 - val_mape: 98.6753\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 5771025408.0000 - mape: 98.6192 - val_loss: 4713084928.0000 - val_mape: 98.6582\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5770050048.0000 - mape: 98.6009 - val_loss: 4712252416.0000 - val_mape: 98.6420\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 5769080832.0000 - mape: 98.5851 - val_loss: 4711396352.0000 - val_mape: 98.6253\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 5768114176.0000 - mape: 98.5657 - val_loss: 4710548992.0000 - val_mape: 98.6088\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5767132672.0000 - mape: 98.5488 - val_loss: 4709652992.0000 - val_mape: 98.5913\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5766123008.0000 - mape: 98.5311 - val_loss: 4708776960.0000 - val_mape: 98.5742\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5765135872.0000 - mape: 98.5128 - val_loss: 4707898368.0000 - val_mape: 98.5571\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5764123648.0000 - mape: 98.4955 - val_loss: 4707003392.0000 - val_mape: 98.5396\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5763112960.0000 - mape: 98.4773 - val_loss: 4706114560.0000 - val_mape: 98.5223\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 5762091008.0000 - mape: 98.4610 - val_loss: 4705230336.0000 - val_mape: 98.5050\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5761084416.0000 - mape: 98.4427 - val_loss: 4704340480.0000 - val_mape: 98.4876\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5760060416.0000 - mape: 98.4246 - val_loss: 4703432192.0000 - val_mape: 98.4699\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 5759029248.0000 - mape: 98.4045 - val_loss: 4702556160.0000 - val_mape: 98.4528\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 1s 94ms/step - loss: 5758018048.0000 - mape: 98.3884 - val_loss: 4701630976.0000 - val_mape: 98.4348\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 5756966400.0000 - mape: 98.3692 - val_loss: 4700675072.0000 - val_mape: 98.4161\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 5755893760.0000 - mape: 98.3506 - val_loss: 4699749888.0000 - val_mape: 98.3980\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5754854912.0000 - mape: 98.3307 - val_loss: 4698867200.0000 - val_mape: 98.3808\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 5753822208.0000 - mape: 98.3128 - val_loss: 4697922560.0000 - val_mape: 98.3623\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 5752750592.0000 - mape: 98.2934 - val_loss: 4697003008.0000 - val_mape: 98.3443\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5751692800.0000 - mape: 98.2744 - val_loss: 4696046592.0000 - val_mape: 98.3257\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5750606848.0000 - mape: 98.2559 - val_loss: 4695122432.0000 - val_mape: 98.3076\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5749547008.0000 - mape: 98.2361 - val_loss: 4694148608.0000 - val_mape: 98.2886\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5748438016.0000 - mape: 98.2158 - val_loss: 4693175808.0000 - val_mape: 98.2696\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 5747339264.0000 - mape: 98.1975 - val_loss: 4692224512.0000 - val_mape: 98.2510\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 5746251264.0000 - mape: 98.1774 - val_loss: 4691249664.0000 - val_mape: 98.2319\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5745138176.0000 - mape: 98.1574 - val_loss: 4690276352.0000 - val_mape: 98.2129\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 5744014336.0000 - mape: 98.1379 - val_loss: 4689277952.0000 - val_mape: 98.1933\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 5742886400.0000 - mape: 98.1171 - val_loss: 4688309248.0000 - val_mape: 98.1744\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 1s 105ms/step - loss: 5741777408.0000 - mape: 98.0984 - val_loss: 4687311360.0000 - val_mape: 98.1549\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 5740654080.0000 - mape: 98.0769 - val_loss: 4686345216.0000 - val_mape: 98.1360\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 5739535360.0000 - mape: 98.0575 - val_loss: 4685319680.0000 - val_mape: 98.1159\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5738373120.0000 - mape: 98.0368 - val_loss: 4684358144.0000 - val_mape: 98.0971\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 1s 101ms/step - loss: 5737270272.0000 - mape: 98.0181 - val_loss: 4683342848.0000 - val_mape: 98.0772\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 5736109568.0000 - mape: 97.9965 - val_loss: 4682336768.0000 - val_mape: 98.0575\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 5734961664.0000 - mape: 97.9764 - val_loss: 4681339904.0000 - val_mape: 98.0379\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5733808640.0000 - mape: 97.9573 - val_loss: 4680282112.0000 - val_mape: 98.0173\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5732613632.0000 - mape: 97.9359 - val_loss: 4679233536.0000 - val_mape: 97.9967\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5731437568.0000 - mape: 97.9125 - val_loss: 4678202880.0000 - val_mape: 97.9765\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 5730255360.0000 - mape: 97.8933 - val_loss: 4677178368.0000 - val_mape: 97.9564\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 1s 108ms/step - loss: 5729086464.0000 - mape: 97.8710 - val_loss: 4676146688.0000 - val_mape: 97.9362\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 1s 103ms/step - loss: 5727899648.0000 - mape: 97.8506 - val_loss: 4675076608.0000 - val_mape: 97.9153\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 5726686720.0000 - mape: 97.8286 - val_loss: 4674025984.0000 - val_mape: 97.8947\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 1s 92ms/step - loss: 5725489152.0000 - mape: 97.8059 - val_loss: 4672967680.0000 - val_mape: 97.8739\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 1s 89ms/step - loss: 5724262912.0000 - mape: 97.7872 - val_loss: 4671849984.0000 - val_mape: 97.8520\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 5723023360.0000 - mape: 97.7623 - val_loss: 4670804992.0000 - val_mape: 97.8315\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 5721821696.0000 - mape: 97.7423 - val_loss: 4669723648.0000 - val_mape: 97.8103\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 1s 111ms/step - loss: 5720589312.0000 - mape: 97.7209 - val_loss: 4668679168.0000 - val_mape: 97.7898\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 5719389184.0000 - mape: 97.6984 - val_loss: 4667601920.0000 - val_mape: 97.7687\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5718152704.0000 - mape: 97.6768 - val_loss: 4666517504.0000 - val_mape: 97.7474\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 5716916224.0000 - mape: 97.6530 - val_loss: 4665435136.0000 - val_mape: 97.7261\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 5715672576.0000 - mape: 97.6330 - val_loss: 4664320000.0000 - val_mape: 97.7043\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 5714404352.0000 - mape: 97.6100 - val_loss: 4663232512.0000 - val_mape: 97.6829\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 5713160704.0000 - mape: 97.5861 - val_loss: 4662108160.0000 - val_mape: 97.6608\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 5711886336.0000 - mape: 97.5644 - val_loss: 4661007872.0000 - val_mape: 97.6392\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "keras.callbacks.History"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = train_rnn_model(rnn_model_3, patience=5, epochs=200)\n",
    "plt.plot(history.history['mape'])\n",
    "plt.plot(history.history['val_mape'])\n",
    "plt.show();\n",
    "type(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5d3333e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(overfit_es), overfit_es <class 'list'> [2, 6, 6, 5, 6]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10039/195786074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# print(\"No early stopping\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_series\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_rnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn_model_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_series\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverfit_es\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mape'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_series' is not defined"
     ]
    }
   ],
   "source": [
    "### Train model #1n_series = [50, 150, 200, 300, 400]\n",
    "overfit_es =   [2, 6, 6, 5, 6 ]\n",
    "print('type(overfit_es), overfit_es', type(overfit_es), overfit_es)\n",
    "# if overfit_es:\n",
    "#     print(\"early stopping\")\n",
    "#     history = train_rnn_model(patience=overfit_es)\n",
    "# else:\n",
    "# print(\"No early stopping\")\n",
    "for i in range(len(train_series)):\n",
    "    history = train_rnn_model(model=rnn_model_3, epochs=train_series[i], patience=overfit_es[i])\n",
    "    plt.plot(history.history['mape'])\n",
    "    plt.plot(history.history['val_mape'])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1950356",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RNN model #3 architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b325a69",
   "metadata": {},
   "source": [
    "#### 🚀 The **LSTM (= Long Short Term Memory)** with their ability to *avoid the vanishing gradient problem*, should be preferred over a SimpleRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Architecture\n",
    "\"\"\"   - 3rd model layers architecture (simple -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "> LSTM\n",
    "\"\"\"\n",
    "rnn_model_3 = Sequential()\n",
    "rnn_model_3.add(normalizer) # Using the Normalization layer to standardize the datapoints during the forward pass\n",
    "# Input len(train) (input_shape=(?,?))\n",
    "rnn_model_3.add(LSTM(units=30, activation='tanh'))  ## , input_shape=(?,?))) without a Normalizer layer\n",
    "# output return sequences = True\n",
    "rnn_model_3.add(Dense(10, activation = 'relu')) ## add 1 or more 'relu' layers\n",
    "# Output 10 only, no more RNN just dropout()\n",
    "# rnn_model_3.add(layers.Dropout(0.3)) ## if RNN model over-fit\n",
    "rnn_model_3.add(Dense(n_pred, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae1226",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile model #3 with 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f878a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compiling with 'rmsprop' rather than 'adam' (recommended)\n",
    "optimizer = RMSprop(\n",
    "                learning_rate=0.001,\n",
    "                rho=0.9,\n",
    "                momentum=0.0,\n",
    "                epsilon=1e-07,\n",
    "                centered=False\n",
    "            )\n",
    "rnn_model_3.compile(loss='mse',\n",
    "              optimizer= optimizer, # optimizer='rmsprop'    <- adapt learning rate\n",
    "                 metrics='mape')  # Recommended optimizer for RNNs\n",
    "rnn_model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1470a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a652e-f059-4adf-bf05-62b7120a24d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RNN model #3 architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d57380-7866-4ec5-8e40-b86653234646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Architecture\n",
    "\"\"\"   - 3rd model layers architecture (simple -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "> LSTM\n",
    "\"\"\"\n",
    "rnn_model_3 = Sequential()\n",
    "rnn_model_3.add(normalizer) # Using the Normalization layer to standardize the datapoints during the forward pass\n",
    "# Input len(train) (input_shape=(?,?))\n",
    "rnn_model_3.add(LSTM(units=30, activation='tanh'))  ## , input_shape=(?,?))) without a Normalizer layer\n",
    "# output return sequences = True\n",
    "rnn_model_3.add(Dense(10, activation = 'relu')) ## add 1 or more 'relu' layers\n",
    "# Output 10 only, no more RNN just dropout()\n",
    "# rnn_model_3.add(layers.Dropout(0.3)) ## if RNN model over-fit\n",
    "rnn_model_3.add(Dense(n_pred, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbe63f-114d-4717-a404-0aa7b96de1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile model #3 with 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524eb0a-0117-4006-af85-9f8235e96cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compiling with 'rmsprop' rather than 'adam' (recommended)\n",
    "optimizer = RMSprop(\n",
    "                learning_rate=0.001,\n",
    "                rho=0.9,\n",
    "                momentum=0.0,\n",
    "                epsilon=1e-07,\n",
    "                centered=False\n",
    "            )\n",
    "rnn_model_3.compile(loss='mse',\n",
    "              optimizer= optimizer, # optimizer='rmsprop'    <- adapt learning rate\n",
    "                 metrics='mape')  # Recommended optimizer for RNNs\n",
    "rnn_model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8cc51a-a8a3-4a61-9c9e-96317f159d50",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecee49a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Training\n",
    "from typing import overload\n",
    "\n",
    "def train_rnn_model(rnn_model_3, patience=2, epochs=200, (X_val, y_val)=(0, 0)):\n",
    "    es = EarlyStopping(monitor = 'val_loss',\n",
    "                    patience = patience,\n",
    "                    verbose = 0,\n",
    "                    restore_best_weights = True)\n",
    "    # The fit\n",
    "    history =  rnn_model_3.fit(X_train, y_train, \n",
    "            validation_split=0.1, # Auto split for validation data\n",
    "                ## validation_data = (X_val, y_val), # To be created manually if needed\n",
    "            batch_size = 16,\n",
    "            epochs = epochs,\n",
    "            callbacks = [es],\n",
    "            verbose=1)\n",
    "    return history\n",
    "\n",
    "\n",
    "print(type(overfit_es), overfit_es)\n",
    "# if overfit_es:\n",
    "#     print(\"early stopping\")\n",
    "#     history = train_rnn_model(patience=overfit_es)\n",
    "# else:\n",
    "# print(\"No early stopping\")\n",
    "# history = train_rnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739df8e1-5a54-4634-a074-e644a6a796a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min(history.history['mape'])\n",
    "\n",
    "# print(\"adjust early stopping\")\n",
    "# overfit_es = [d[0]+1 for d in enumerate(history.history['mape']) if d[1] == min(history.history['mape'])][0]\n",
    "# overfit_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43e359-c428-43f9-9369-f0804a5acdac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min(history.history['mape']), max(history.history['mape']), history.history['mape'] # blue line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f6eb0-e734-48c4-a455-49949ea62a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max(history.history['val_mape']), history.history['val_mape'] # orange line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba3da5-6613-418e-9919-2f7d50e0078e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model #1 evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed1ac5-3b8a-4049-abe8-9431de2121c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Evaluating\n",
    "# The prediction (one per sequence/city)\n",
    "y_pred = rnn_model.predict(X_test) \n",
    "print(y_pred.shape)\n",
    "# Distribution of the predictions\n",
    "pd.DataFrame(y_pred).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32232f29-fc87-49fc-9f6f-11dcb25a9f92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time Series Forecasting with model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a68310-d512-4825-a2c4-21cb68e5f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your code below\n",
    "assert y_pred.shape == (n_seq_test, n_pred)\n",
    "# Distribution of the real values y_train\n",
    "pd.DataFrame(y_train).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8cad73-73e8-4211-908a-3789b7a03497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the real values y_train\n",
    "pd.DataFrame(y_train).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train model #1n_series = [50, 150, 200, 300, 400]\n",
    "overfit_es =   [2, 6, 6, 5, 6 ]\n",
    "print('type(overfit_es), overfit_es', type(overfit_es), overfit_es)\n",
    "# if overfit_es:\n",
    "#     print(\"early stopping\")\n",
    "#     history = train_rnn_model(patience=overfit_es)\n",
    "# else:\n",
    "# print(\"No early stopping\")\n",
    "for i in range(len(train_series)):\n",
    "    history = train_rnn_model(model=rnn_model_2, epochs=train_series[i], patience=overfit_es[i])\n",
    "    plt.plot(history.history['mape'])\n",
    "    plt.plot(history.history['val_mape'])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f576952-8105-43b3-9d97-39d19277c207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6cdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3557ab-55e0-4ae2-a289-212d608dc237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(X_val=0, y_val=0):\n",
    "    [print(f'validation_data=(X_val, y_val),') if (X_val!=0 or y_val!=0) else print(f'validation_split=0.1,')]\n",
    "    return True\n",
    "\n",
    "train_rnn(),train_rnn((1),(0))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('shims')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e588d92b224e11b16adbbadd39936dea13a6488171770263a646fc57f44563d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
