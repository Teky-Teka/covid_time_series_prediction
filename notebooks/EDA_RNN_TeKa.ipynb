{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cac72ae-9be5-43d4-87d3-b2319a0f757b",
   "metadata": {},
   "source": [
    "# Deep Learning Time Series COVID-19 Cases Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa5e65-751f-41c5-9c0b-6151844fd2be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de425903-9365-4407-8ae8-9b20a6e41dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import requests\n",
    "import pandas_profiling\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332849e5-8682-4079-8266-8a22c70d7d38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee22a40-a282-4e4f-bf18-ce8a7633b59c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7e9b20-7339-486d-8ebc-21b0394c5e5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### By country over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c36f91-5db2-4aa7-b598-45ae52f2dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_time_series(feature='stringency', start_date='2020-02-14', end_date='2021-02-14'):\n",
    "    \"\"\"\n",
    "    Get stringency time series for each countries requesting API.\n",
    "    Returns json dict with TS between start_date and end_date like 'YYYY-MM-DD'.\n",
    "    \"\"\"\n",
    "    url = f'https://covidtrackerapi.bsg.ox.ac.uk/api/v2/{feature}/date-range/{start_date}/{end_date}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return ''\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f6689-5b7f-42e3-891b-57367b4658e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_time_series_api = fetch_time_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6bad4c-3c99-4620-aead-b7951a993db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k, [c for c in v if c == 'VNM'])  for k, v in countries_time_series_api.items()  if k == 'countries' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59acb5e4-2aee-4aa5-be96-ac8af9d3a96a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[([([([(vee)  for kaaa, veee  in vee.items() if kaaa in ['date_value', 'confirmed']  ])  for kaa, vee  in ve.items() if kaa =='VNM'   ])  for ka, ve  in v.items() ])  for k, v in countries_time_series_api.items() if k=='data'   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb51b76-85af-4077-8db0-4b74529104a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[(k, [(ka, [(kaa, vee)  for kaa, vee  in ve.items() if kaa =='USA'   ])  for ka, ve  in v.items() ])  for k, v in countries_time_series_api.items() if k=='data'   ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b518b601-27e8-4411-9b10-165c94c89c3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Country data for a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e858c-c9e9-4d78-9d94-804e06fbf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(country='USA', date='2020-08-14'):\n",
    "    \"\"\"\n",
    "    Get stringency data for one country {ALPHA-3} requesting API.\n",
    "    Returns json dict with data for country like 'AAA' and specific date and like 'YYYY-MM-DD'.\n",
    "    \"\"\"\n",
    "    url = f'https://covidtrackerapi.bsg.ox.ac.uk/api/v2/stringency/actions/{country}/{date}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return ''\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0debbac8-54a8-482a-b339-d5fa249c4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_data_api = fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c13eee-1681-40ca-b0d2-2ab21437191f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[[';'.join([str(kk) for kk, vv in d.items()]) for i, d in enumerate(v) if type(d) == dict and i == 0] for v in country_data_api.values()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81f0b8-9fc7-4e38-8e24-99408857cb90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[[';'.join([str(vv) for kk, vv in d.items()]) for d in v if type(d) == dict] for v in country_data_api.values()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869ee50-edb3-423d-8a75-f05af3f32afa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [';'.join([str(vv) for vv in v]) for v in country_data_api.values()][-1]\n",
    "[';'.join([str(kk) for kk in v]) for k, v in country_data_api.items()][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad4771-e464-4eb1-86f5-c5c480cea8d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7c791-f898-4106-b9a9-f1221fcfb1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Read URL**, **Get CSV files** and **store CSV in local**  *(optional do it at begining or to refresh CSV data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318d9af-8148-4bbc-9dff-7359600f778d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **get_database_to_csv()** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d42cd6c-5efd-4cad-b74b-d134e2653dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database_to_csv(url, csv_list, path='', db_grid=[]) -> list:\n",
    "    \"\"\"\n",
    "    function that take in parameter:\n",
    "     - a root URL (string) to get the CSV data,\n",
    "     - a list of CSV files,\n",
    "     - a path (string) to store CSV in local,\n",
    "     - a grid (list of list) to add in the CSV filename, URL, local path.     \n",
    "    and returns the gird updated with the CSVs of the list\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ### Create a database grid (list of list) with all CSVs and associated URLs\n",
    "    # print('db_grid', db_grid)\n",
    "    #### Data project directory (if empty do not store CSV in local)\n",
    "    # print('path', path)\n",
    "    ### Website CSV datasets URL\n",
    "    # print('url', url)\n",
    "    #### List of CSVs of Website to retrieve\n",
    "    # print('csv_list', csv_list)\n",
    "\n",
    "    #### Length of grid aka number of CSVs already stored in grid\n",
    "    len_grid = len(db_grid)\n",
    "\n",
    "    for l in range(len(csv_list)):\n",
    "        # g = l + len_grid\n",
    "        sub_list = []       \n",
    "        sub_list.append(csv_list[l]) ## 1st pos°: CSV filename\n",
    "        sub_list.append(url + csv_list[l]) ## 2nd pos°: URL + CSV\n",
    "        if len(data_dir) > 0: ## store CSV in local\n",
    "            sub_list.append(data_dir + csv_list[l]) ## 3rd pos°: local data path + CSV\n",
    "            !curl -L \"{url + csv_list[l]}\" > {data_dir + csv_list[l]} ## curl <URL>/<CSV> => <path>\n",
    "        print('sub_list', sub_list)\n",
    "        db_grid.append(sub_list)\n",
    "\n",
    "    ### Return a database grid (list of list) with all CSVs and associated URLs\n",
    "    return db_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa98a-c3ba-4108-98bd-5a0b4af0cd17",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Get database to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c62c742-44a6-46c0-bfca-d5fece235ee2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1994k  100 1994k    0     0  6329k      0 --:--:-- --:--:-- --:--:-- 6455k\n",
      "sub_list ['confirmed_cases.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/confirmed_cases.csv', '../raw_data/confirmed_cases.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1888k  100 1888k    0     0  5881k      0 --:--:-- --:--:-- --:--:-- 6013k\n",
      "sub_list ['stringency_index_avg.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/stringency_index_avg.csv', '../raw_data/stringency_index_avg.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1927k  100 1927k    0     0  4964k      0 --:--:-- --:--:-- --:--:-- 5059k\n",
      "sub_list ['government_response_index_avg.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/government_response_index_avg.csv', '../raw_data/government_response_index_avg.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1891k  100 1891k    0     0  5757k      0 --:--:-- --:--:-- --:--:-- 5893k\n",
      "sub_list ['containment_health_index_avg.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/containment_health_index_avg.csv', '../raw_data/containment_health_index_avg.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1325k  100 1325k    0     0  3732k      0 --:--:-- --:--:-- --:--:-- 3787k\n",
      "sub_list ['economic_support_index.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/economic_support_index.csv', '../raw_data/economic_support_index.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1021k  100 1021k    0     0  3215k      0 --:--:-- --:--:-- --:--:-- 3295k\n",
      "sub_list ['h7_vaccination_policy.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/h7_vaccination_policy.csv', '../raw_data/h7_vaccination_policy.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1021k  100 1021k    0     0  3402k      0 --:--:-- --:--:-- --:--:-- 3475k\n",
      "sub_list ['c1m_school_closing.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c1m_school_closing.csv', '../raw_data/c1m_school_closing.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1021k  100 1021k    0     0  3608k      0 --:--:-- --:--:-- --:--:-- 3715k\n",
      "sub_list ['c2m_workplace_closing.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c2m_workplace_closing.csv', '../raw_data/c2m_workplace_closing.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1021k  100 1021k    0     0  2202k      0 --:--:-- --:--:-- --:--:-- 2240k\n",
      "sub_list ['c3m_cancel_public_events.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c3m_cancel_public_events.csv', '../raw_data/c3m_cancel_public_events.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1021k  100 1021k    0     0  3071k      0 --:--:-- --:--:-- --:--:-- 3124k\n",
      "sub_list ['c4m_restrictions_on_gatherings.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c4m_restrictions_on_gatherings.csv', '../raw_data/c4m_restrictions_on_gatherings.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1021k  100 1021k    0     0  3720k      0 --:--:-- --:--:-- --:--:-- 3784k\n",
      "sub_list ['c6m_stay_at_home_requirements.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/c6m_stay_at_home_requirements.csv', '../raw_data/c6m_stay_at_home_requirements.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1021k  100 1021k    0     0  3109k      0 --:--:-- --:--:-- --:--:-- 3163k\n",
      "sub_list ['h6m_facial_coverings.csv', 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/h6m_facial_coverings.csv', '../raw_data/h6m_facial_coverings.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9374k  100 9374k    0     0  14.3M      0 --:--:-- --:--:-- --:--:-- 14.4M\n",
      "sub_list ['vaccinations.csv', 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations.csv', '../raw_data/vaccinations.csv']\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1886k  100 1886k    0     0  5807k      0 --:--:-- --:--:-- --:--:-- 5876k\n",
      "sub_list ['vaccinations-by-age-group.csv', 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations-by-age-group.csv', '../raw_data/vaccinations-by-age-group.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'confirmed_cases.csv': 0,\n",
       " 'stringency_index_avg.csv': 1,\n",
       " 'government_response_index_avg.csv': 2,\n",
       " 'containment_health_index_avg.csv': 3,\n",
       " 'economic_support_index.csv': 4,\n",
       " 'h7_vaccination_policy.csv': 5,\n",
       " 'c1m_school_closing.csv': 6,\n",
       " 'c2m_workplace_closing.csv': 7,\n",
       " 'c3m_cancel_public_events.csv': 8,\n",
       " 'c4m_restrictions_on_gatherings.csv': 9,\n",
       " 'c6m_stay_at_home_requirements.csv': 10,\n",
       " 'h6m_facial_coverings.csv': 11,\n",
       " 'vaccinations.csv': 12,\n",
       " 'vaccinations-by-age-group.csv': 13}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Data project directory\n",
    "data_dir = '../raw_data/'\n",
    "\n",
    "### Oxford Master data time series URL\n",
    "url_root_oxford = 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/'\n",
    "\n",
    "#### List of CSVs of Oxford database Feel free to add more feature...\n",
    "csv_list = ['confirmed_cases.csv', 'stringency_index_avg.csv', 'government_response_index_avg.csv', \n",
    "            'containment_health_index_avg.csv', 'economic_support_index.csv', 'h7_vaccination_policy.csv', \n",
    "            'c1m_school_closing.csv', 'c2m_workplace_closing.csv', 'c3m_cancel_public_events.csv', \n",
    "            'c4m_restrictions_on_gatherings.csv', 'c6m_stay_at_home_requirements.csv', 'h6m_facial_coverings.csv'\n",
    "           ]\n",
    "# print(csv_list)\n",
    "    \n",
    "### Vacinations Dataset URLs\n",
    "url_root_vaccinations = 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/'\n",
    "\n",
    "#### List of CSVs of Vaccinations database\n",
    "csv_list_vax = ['vaccinations.csv', 'vaccinations-by-age-group.csv']\n",
    "# print(csv_list_vax)\n",
    "\n",
    "### Create a database grid (list of list) with all CSVs and associated URLs\n",
    "# db_grid = [[]]\n",
    "# print(db_grid)\n",
    "### Insert into database grid all CSVs and associated URLs from Oxford website\n",
    "db_grid = get_database_to_csv(url_root_oxford, csv_list, data_dir) ## uncomment to store CSV\n",
    "### Insert into database grid all CSVs and associated URLs from vaccinations website\n",
    "db_grid = get_database_to_csv(url_root_vaccinations, csv_list_vax, data_dir, db_grid)\n",
    "# print('db_grid', db_grid)\n",
    "\n",
    "# Stack all csl in the list\n",
    "csv_list += csv_list_vax\n",
    "\n",
    "# transform list into dict:\n",
    "csv = dict(zip(csv_list, [v[0] for v in enumerate(csv_list)])) # if v[1] == 'containment_health_index_avg.csv'\n",
    "csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecf123-5e8d-4e1e-b337-e0164c78fa4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### *Get database to csv one by one*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd459c-b852-457f-8a9d-ab54d4ca611b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### Target URLs\n",
    "url_cases = url_root_oxford + 'confirmed_cases.csv'\n",
    "url_deaths = url_root_oxford + 'confirmed_deaths.csv'\n",
    "\n",
    "#### Index URLs\n",
    "url_id1= url_root_oxford + csv_i1 ## index_strigency\n",
    "url_id2 = url_root_oxford + csv_i2 ## index_gov_resp\n",
    "url_id3_health = url_root_oxford + csv_i3 ## index_health\n",
    "url_id4 = url_root_oxford + csv_i4 ## index_economic\n",
    "\n",
    "#### C[1-8] URLs\n",
    "url_c1 = url_root_oxford + csv_c1 ## 'C1;School closing;'\n",
    "url_c2 = url_root_oxford + csv_c1 ## 'C2;Workplace closing;'\n",
    "url_c3 = url_root_oxford + csv_c3 ## 'C3;Cancel public events;'\n",
    "url_c4 = url_root_oxford + csv_c4 ## 'C4;Restrictions on gatherings;'\n",
    "url_c5 = url_root_oxford + csv_c5 ## 'C5;Close public transport'\n",
    "url_c6 = url_root_oxford + csv_c6 ## 'C6;Stay at home requirements;'\n",
    "url_c7 = url_root_oxford + csv_c7 ## 'C7;Restrictions on internal movement;'\n",
    "url_c8 = url_root_oxford + csv_c8 ##  'C8;International travel controls;'\n",
    " \n",
    "#### E[1-4] URLs\n",
    "url_e1 = url_root_oxford + csv_e1 ## 'E1;Income support;'\n",
    "url_e2 = url_root_oxford + csv_e2 ## 'E2;Debt/contract relief;'\n",
    "url_e3 = url_root_oxford + csv_e3 ## 'E3;Fiscal measures;'\n",
    "url_e4 = url_root_oxford + csv_e4 ## 'E4;International support;'\n",
    " \n",
    "#### H[1-8] URLs\n",
    "url_h1 = url_root_oxford + csv_h1 ## 'H1;Public information campaigns;'\n",
    "url_h2 = url_root_oxford + csv_h2 ## 'H2;Testing policy'\n",
    "url_h3 = url_root_oxford + csv_h3 ## 'H3;Contact tracing;'\n",
    "url_h3 = url_root_oxford + csv_h4 ## 'H4;Emergency investment in healthcare;0;0;None;None;None;USD Value',\n",
    "url_h3 = url_root_oxford + csv_h5 ## 'H5;Investment in vaccines;0;0;None;None;None;USD Value',\n",
    "url_h3 = url_root_oxford + csv_h6 ## 'H6;Facial Coverings;0;0;None;None;None;General;No policy',\n",
    "url_h3 = url_root_oxford + csv_h7 ## 'H7;Vaccination policy;0;0;None;None;None;Government funded;No availability',\n",
    "url_h3 = url_root_oxford + csv_h8 ## 'H8;Protection of elderly people;1;1;True;True;None;General;Recommended protections',\n",
    "\n",
    "#### V[1-4] URLs\n",
    "url_v1 = url_root_oxford + csv_h1 ## 'V1;Vaccine Prioritisation;-2;-2;None;None;None',\n",
    "url_v2 = url_root_oxford + csv_h2 ## 'V2;Vaccine Availability;-2;-2;None;None;None',\n",
    "url_v3 = url_root_oxford + csv_h3 ## 'V3;Vaccine Financial Support;-2;-2;None;None;None',\n",
    "url_v4 = url_root_oxford + csv_h4 ## 'V4;Mandatory Vaccination;-2;-2;None;None;None']\n",
    "\n",
    "### Vacinations Dataset URLs\n",
    "url_root_vaccinations = 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/'\n",
    "url_v5  = url_root_vaccinations + csv_v5 ## '/vaccinations.csv'\n",
    "url_v6 = url_root_vaccinations + csv_v6 ## 'vaccinations-by-age-group.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecccd7d-f9bd-46d8-8e29-6e390f6ffb91",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "#### DataFrame Index\n",
    "!curl -L \"{url_i1}\" > {data_dir}{csv_i1}\n",
    "!curl -L \"{url_i2}\" > {data_dir}{csv_i2}\n",
    "!curl -L \"{url_i3}\" > {data_dir}{csv_i3}\n",
    "!curl -L \"{url_i4}\" > {data_dir}{csv_i4}\n",
    "!curl -L \"{url_c1}\" > {data_dir}{csv_c1}\n",
    "!curl -L \"{url_c2}\" > {data_dir}{csv_c2}\n",
    "!curl -L \"{url_c3}\" > {data_dir}{csv_c3}\n",
    "!curl -L \"{url_c4}\" > {data_dir}{csv_c4}\n",
    "!curl -L \"{url_c5}\" > {data_dir}{csv_c5}\n",
    "!curl -L \"{url_c6}\" > {data_dir}{csv_c6}\n",
    "!curl -L \"{url_c7}\" > {data_dir}{csv_c7}\n",
    "!curl -L \"{url_c8}\" > {data_dir}{csv_c8}\n",
    "\n",
    "df_raw_school_closing=pd.read_csv('../raw_data/c1m_school_closing.csv')\n",
    "df_raw_workplace_closing=pd.read_csv('../raw_data/c2m_workplace_closing.csv')\n",
    "df_raw_cancel_public_event=pd.read_csv('../raw_data/c3m_cancel_public_events.csv')\n",
    "df_raw_restriction_on_gathering=pd.read_csv('../raw_data/c4m_restrictions_on_gatherings.csv')\n",
    "df_raw_stay_at_home=pd.read_csv('../raw_data/c6m_stay_at_home_requirements.csv')\n",
    "df_raw_international_travel=pd.read_csv('../raw_data/c6m_stay_at_home_requirements.csv')\n",
    "df_raw_goverment_response=pd.read_csv('../raw_data/government_response_index_avg.csv')\n",
    "df_raw_facial_covering=pd.read_csv('../raw_data/h6m_facial_coverings.csv')\n",
    "df_raw_vacination_policy=pd.read_csv('../raw_data/h7_vaccination_policy.csv')\n",
    "\n",
    "\n",
    "\n",
    "#### Vaccination\n",
    "!curl -L \"{url_vaccination}\" > {data_dir}{vaccination_csv}\n",
    "!curl -L \"{url_ages}\" > {data_dir}{ages_csv}\n",
    "\n",
    "#### CSV target\n",
    "!curl -L \"{url_cases}\" > {data_dir}{cases_csv}\n",
    "!curl -L \"{url_deaths}\" > {data_dir}{deaths_csv}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc67099-9098-47c4-9e1d-b2754e07cd70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Read CSV** and **Set raw dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e6d96-2374-43c5-a9b7-b707e20bdcdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_grid[csv_dict['containment_health_index_avg.csv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a647dd56-8eaf-4f56-b52f-173e818e245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_gov_response = pd.read_csv(data_dir + 'government_response_index_avg.csv')\n",
    "df_raw_health = pd.read_csv(data_dir + 'containment_health_index_avg.csv')\n",
    "df_raw_economic = pd.read_csv(data_dir + 'economic_support_index.csv')\n",
    "\n",
    "#### Vaccination\n",
    "df_raw_vaccination = pd.read_csv(data_dir + 'vaccinations.csv')\n",
    "df_raw_ages = pd.read_csv(data_dir + 'vaccinations-by-age-group.csv')\n",
    "\n",
    "\n",
    "#### Data Frame target\n",
    "df_raw_cases = pd.read_csv(data_dir + 'confirmed_deaths.csv')\n",
    "df_raw_deaths = pd.read_csv(data_dir + 'confirmed_deaths.csv')\n",
    "\n",
    "#### Data multiple\n",
    "# df_raw_confirmed_cases=pd.read_csv(url_cases)\n",
    "# df_raw_death=pd.read_csv(data_dir + 'confirmed_deaths.csv')\n",
    "df_raw_school_closing=pd.read_csv(data_dir + 'c1m_school_closing.csv')\n",
    "df_raw_workplace_closing=pd.read_csv(data_dir + 'c2m_workplace_closing.csv')\n",
    "df_raw_cancel_public_event=pd.read_csv(data_dir + 'c3m_cancel_public_events.csv')\n",
    "df_raw_restriction_on_gathering=pd.read_csv(data_dir + 'c4m_restrictions_on_gatherings.csv')\n",
    "df_raw_stay_at_home=pd.read_csv(data_dir + 'c6m_stay_at_home_requirements.csv')\n",
    "df_raw_international_travel=pd.read_csv(data_dir + 'c6m_stay_at_home_requirements.csv')\n",
    "df_raw_goverment_response=pd.read_csv(data_dir + 'government_response_index_avg.csv')\n",
    "df_raw_facial_covering=pd.read_csv(data_dir + 'h6m_facial_coverings.csv')\n",
    "df_raw_vacination_policy=pd.read_csv(data_dir + 'h7_vaccination_policy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82145c-891d-47d7-8f43-4680c1ccdd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af80fd-116d-4c66-a2d5-44016cb3598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_cases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780e433-b780-4736-9011-36e69a97910d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory Data Analyzis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca627f6-23e4-4243-8a68-e0b3108b21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_cases.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75735fc5-e04d-46ae-9d96-92dccdc1aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get VietNam country dataset\n",
    "vn_data = df_raw_cases.loc[df_raw_cases['country_code'] == 'VNM'].copy()\n",
    "\n",
    "vn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f336df2-286a-4819-a011-c1ae0d7cdb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# vn_data.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ee15a-c507-4049-9489-1f546a1f0a8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9f66c-7776-4901-ae47-0a91b721f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9490e09-78eb-4563-881a-ea7d9f40b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cases = df_raw_cases.drop(columns=['country_name','region_code','region_name','jurisdiction','Unnamed: 0'])\n",
    "ts_cases = ts_cases.groupby('country_code').agg('sum')\n",
    "ts_cases.transpose()\n",
    "ts_cases.columns.name = 'Dates'\n",
    "ts_cases = ts_cases.fillna(0)\n",
    "# ts_cases.index = pd.to_datetime(ts_cases.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9518a-a848-45c5-b0cf-a1dc2363b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cases = ts_cases.transpose()\n",
    "ts_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e0fb8-f976-4dbe-8243-7a69be38b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a09792-d09e-41ec-9531-f38f8cd32a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_ts_cases = vn_data.drop(columns=['country_name','region_code','region_name','jurisdiction','Unnamed: 0'])\n",
    "vn_ts_cases = vn_ts_cases.groupby('country_code').agg('sum')\n",
    "vn_ts_cases.transpose()\n",
    "vn_ts_cases.columns.name = 'Dates'\n",
    "vn_ts_cases = vn_ts_cases.fillna(0)\n",
    "# ts_cases.index = pd.to_datetime(ts_cases.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5ecb3-6362-430f-bdc8-f8f2298c120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_ts_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54395e-6a75-45b7-a389-7f739b5c35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_ts_cases = vn_ts_cases.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3149186-e348-4abe-8e9f-477ff96bd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_ts_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c7bb40-47ee-4ef3-9465-1a9c6bd2a56c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "country = 'France'\n",
    "\n",
    "def country_output(country, indicator):\n",
    "    \n",
    "    # INDEX FEATURES\n",
    "    country_index = df_gov_response.copy()\n",
    "    country_index = country_index[[country]]\n",
    "    country_index.index.name = country\n",
    "    country_index.columns = ['Gov_response']\n",
    "    country_index['Containment_and_health'] = df_health[[country]]\n",
    "    country_index['Stringency'] = df_strigency[[country]]\n",
    "    country_index['Economics_sup'] = df_economic[[country]]\n",
    "\n",
    "    # POPULATION VACCINATED\n",
    "\n",
    "    country_vaccination = df_vaccination.loc[df_vaccination['location']==country]\n",
    "    country_vaccination = country_vaccination.fillna(method='ffill').drop(columns = 'location')\n",
    "    country_vaccination.index.name = country\n",
    "    country_vaccination = country_vaccination.fillna(0)\n",
    "\n",
    "    # TARGET\n",
    "\n",
    "    country_target = df_cases.copy()\n",
    "    country_target = country_target[[country]]\n",
    "    country_target.index.name = country\n",
    "    country_target.columns = ['total_cases']\n",
    "    country_target['new_cases'] = country_target - country_target.shift(1)\n",
    "    country_target['total_deaths'] = df_deaths[[country]]\n",
    "    country_target['new_deaths'] = df_deaths[[country]] - df_deaths[[country]].shift(1)\n",
    "\n",
    "    country_target['new_cases'].loc[country_target['new_cases'] < 0] = 0\n",
    "    country_target['new_deaths'].loc[country_target['new_deaths'] < 0] = 0\n",
    "\n",
    "    # Days no update counter\n",
    "\n",
    "    def non_uptade(country_target):\n",
    "\n",
    "        counter = 0\n",
    "        x = 1\n",
    "        while country_target['total_deaths'][-x] == 0:\n",
    "            counter += 1\n",
    "            x += 1\n",
    "\n",
    "        return counter\n",
    "\n",
    "    counter = non_uptade(country_target)\n",
    "\n",
    "    # Last Update Data\n",
    "\n",
    "    country_index = country_index[:-counter]\n",
    "    country_vaccination = country_vaccination[:-counter]\n",
    "    country_target = country_target[:-counter]\n",
    "    \n",
    "    return country_index, country_vaccination, country_target\n",
    "\n",
    "country_index, country_vaccination, country_target = country_output(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636afbb-aab0-4500-897b-311961289203",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recurrent Neural Network (sequences data) modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f081b-7ee6-405b-8e13-04bf267ac2e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Samples/Sequences, Observations, Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6427dc3-25b3-4a5a-abba-20e92d67ab1b",
   "metadata": {},
   "source": [
    "X.shape = (n_SEQUENCES, n_OBSERVATIONS, n_FEATURES)\n",
    "\n",
    "y = RNN(X)\n",
    "\n",
    "❗️ Notation $X_{i,j}^{t}$\n",
    "\n",
    " $_{i}$ is the sample/sequence\n",
    " \n",
    " $_{j}$ is the feature measured\n",
    " \n",
    " $^{t}$ is the time at which the observation is seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922fc086-caa8-4117-ada2-60e8f5d85d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq = 50 # ts_cases.shape[0] - 1 # nb of countries (samples)\n",
    "n_obs = 15 # 15 days of training periiod (observations)\n",
    "n_feat = 1 # 1feature: covid cases\n",
    "n_pred = 1 # nb of days of prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83c022-e4ae-4066-a94e-c87274c43314",
   "metadata": {},
   "source": [
    "X = np.array(ts).astype(np.float32)\n",
    "\n",
    "y = np.array([y_a, y_b, y_c]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8151dc-1f0e-4981-91a0-c1164230af26",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- **retrieve dataset** from Alberto\n",
    "\n",
    "    - **clean dataset**: \n",
    "        \n",
    "        - **drop first lines == 0** *(before Covid arrived)*\n",
    "        \n",
    "        - **check Nan**: \n",
    "- **strategy 1 country by country** sequences split as follow:\n",
    "\n",
    "- **strategy 2 one sequence per country**:\n",
    "    - **split X train, set** \n",
    "    - **Pad sequences**\n",
    "    - **create one csv per country**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4fba2-9562-49eb-9b94-7c5ab57fd163",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create sequences (`X`,`y`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188b112-9ee9-4cb9-94d8-43724f36a493",
   "metadata": {},
   "source": [
    "def **subsample_sequence(df, length)** -> pd.DataFrame:\n",
    "\n",
    "function that given a full dataframe `df`:\n",
    "- Create a sub sequences df, with long length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29b8f8-53bc-4bb0-a509-b7b2e1f3321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_sequence(df, length) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given the initial dataframe `df`, return a shorter dataframe sequence of length `length` (eg n_obs).\n",
    "    This shorter sequence should be selected at random\n",
    "    \"\"\"\n",
    "    last_possible = df.shape[0] - length\n",
    "    # How to split sequences? we could do it manually...\n",
    "    random_start = np.random.randint(0, last_possible)\n",
    "    df_sample = df[random_start: random_start+length]\n",
    "    \n",
    "    return df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb7159-4882-4d1a-a579-793c570bede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it \n",
    "assert subsample_sequence(vn_ts_cases, 10).shape  == (10, 1)\n",
    "assert subsample_sequence(vn_ts_cases, 400).shape == (400, 1)\n",
    "subsample_sequence(vn_ts_cases, 10).shape, subsample_sequence(vn_ts_cases, 400).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d51b66-afe3-44ab-bd4a-3a8bce42ee80",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pad `X` missing values with mean values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f77ac8-0106-4c19-9e8a-0f25e985a94d",
   "metadata": {},
   "source": [
    "def **split_subsample_sequence(df,  length, sequence='VNM', df_mean=None)** -> tuple:\n",
    "\n",
    "function that given a full dataframe `df`:\n",
    "- Create a sub sequences df\n",
    "- Stores the value of the covid deaths* (or cases) of the last day as your variable array `y`\n",
    "- Stores all features of previous days as a variable `X`\n",
    "- Returns (`X`, `y`)\n",
    "\n",
    "* *'VNM_covd_deaths'* preference for death prediction, then switch on cases *'VNM_covid_cases'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1d42a-3250-4ae7-be4f-87a8766f92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of a sequence\n",
    "len_seq = n_obs + n_pred\n",
    "# Ex: 16 = 15 + 1\n",
    "len_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d7777-02cf-4205-aec4-69179c182de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subsample_sequence(df,  length, sequence='VNM', y_size=1) -> tuple:\n",
    "    '''\n",
    "    Create one single random (X_sample, y_sample)\n",
    "    containing one sequence each of length `length`\n",
    "    ToDo: Adapt the y size=-1'''\n",
    "    # Trick to save time during potential recursive calls\n",
    "    # if df_mean is None:\n",
    "    #     df_mean = df.mean()\n",
    "    df_subsample = subsample_sequence(df, length)\n",
    "    y_sample = df_subsample.iloc[length - y_size][sequence] # ['VNM'] ['VNM_covid_cases', 'VNM_covd_deaths'] \n",
    "    # Case y_sample is NaN: redraw !\n",
    "    # if y_sample != y_sample: # A value is not equal to itself only for NaN\n",
    "    #         X_sample, y_sample = split_subsample_sequence(df, length, df_mean) # Recursive call !!!\n",
    "    #         return np.array(X_sample), np.array(y_sample)    \n",
    "    X_sample = df_subsample[0:length - y_size]\n",
    "    # Case X_sample has some NaNs\n",
    "    # if X_sample.isna().sum().sum() !=0:\n",
    "    #    X_sample = X_sample.fillna(compute_means(X_sample, df_mean))\n",
    "    #    X_sample = X_sample.values\n",
    "\n",
    "    return np.array(X_sample), np.array(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993c868-606c-4d31-ac8d-997bc85d63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it\n",
    "(X_sample, y_sample) = split_subsample_sequence(vn_ts_cases, length=len_seq, y_size=n_pred)\n",
    "assert X_sample.shape == (n_obs,n_feat)\n",
    "assert y_sample.shape == ()\n",
    "X_sample.shape, y_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e6437-7538-4c29-b8d9-d00d4d804064",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generates an entire dataset of multiple subsamples with shape $(X, y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb0927-e52b-4d41-8dcb-6ca6f204a1f5",
   "metadata": {},
   "source": [
    "def **get_X_y(df, n_sequences, length)** -> tuple:\n",
    "\n",
    "function to generates an entire dataset of multiple subsamples suitable for RNN, that is, $(X, y)$ of shape:\n",
    "\n",
    "```python\n",
    "X.shape = (n_sequences, length, n_features)\n",
    "y.shape = (n_sequences, )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c33ac-32c7-45ea-b554-e37f91a87701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(df, n_sequences, length) -> tuple:\n",
    "    '''Return a list of samples (X, y)'''\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(n_sequences):\n",
    "        (xi, yi) = split_subsample_sequence(df, length)\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "        \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e4d481-caeb-4f65-90cf-44c386e9a4cb",
   "metadata": {},
   "source": [
    "Generate your dataset $(X, y)$ of `50` sequences, each of `15` observations + the covid cases at the 16-th day to predict\n",
    "\n",
    "n_seq = 50 # ts_cases.shape[0] - 1 # nb of countries (samples)\n",
    "n_obs = 15 # 15 days of training periiod (observations)\n",
    "n_feat = 1 # 1feature: covid cases\n",
    "n_pred = 1 # nb of days of prediction\n",
    "len_seq = 16 # length of a sequence (len_seq = n_obs + n_pred/ Ex: 16 = 15 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1c5f66-370f-4fec-a25b-c923775b025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_X_y(vn_ts_cases, n_sequences=n_seq, length=len_seq)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a9a642-bd2b-4029-a589-1be8947f1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your code below\n",
    "assert X.shape == (50, 15, 1)\n",
    "assert y.shape == (50, )\n",
    "assert np.isnan(X).sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe229ed-38be-485e-9314-5a3c04da8847",
   "metadata": {},
   "source": [
    "### How to split sequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49128bf-f5e8-4319-8635-fa1f63c29ceb",
   "metadata": {},
   "source": [
    "- randomly or\n",
    "\n",
    "- manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d29d30-5758-4941-b217-ccefe2116237",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Samples/Sequences, Observations, Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245d337-90d7-47b1-a4ee-b508e8731c39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a11099-3fde-4df6-bb58-222e55e85dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1. Train splitting\n",
    "# Let's keep the last 20% of the values out for testing purposes\n",
    "train_size = 0.8 ## 80% of dataset to train\n",
    "index = round(train_size * ts_cases.shape[0])\n",
    "\n",
    "X_train = ts_cases.iloc[:index]\n",
    "X_test = ts_cases.iloc[index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46650e9f-0186-4b2f-a981-70723ebc9f1c",
   "metadata": {},
   "source": [
    "Let's not cross-validate in this challenge to start with 🤯 \n",
    "- Separate `df` into `df_train` and `df_test` such that the first 80% of the dataframe is in the training, and the last 20% in the test set.\n",
    "- Then generate (`X_train`, `y_train`) from `df_train` and (`X_test`, `y_test`) from `df_test`\n",
    "- Ensure that `X_train.shape == (50, 15, 1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f30c3-7747-471f-b64c-f9ac6854f6ad",
   "metadata": {},
   "source": [
    "len_ = int(0.8*ts_cases.shape[0])\n",
    "df_train = ts_cases[:len_] ; df_test = ts_cases[len_:]\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1fd9ed-09d0-442c-8cdd-f30d5dae6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq_test = n_seq // 3 ; n_seq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c4c4c-7de5-4927-8b93-8e40cc8784da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y(df_train, n_seq, len_seq)\n",
    "X_test, y_test = get_X_y(df_test, n_seq_test, len_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd4799-c81a-4505-b9ed-4978b6258ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397c28d-f9f1-4d6c-9ed2-17a617e42352",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Normalization layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50f5c4-faa0-4355-a1fd-a28b28062623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. The Normalization Layer\n",
    "normalizer = Normalization()  # Instantiate a \"normalizer\" layer\n",
    "normalizer.adapt(X_train) # \"Fit\" it on the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a652e-f059-4adf-bf05-62b7120a24d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RNN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d57380-7866-4ec5-8e40-b86653234646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Architecture\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(normalizer) # Using the Normalization layer to standardize the datapoints during the forward pass\n",
    "rnn_model.add(SimpleRNN(units=20, activation='tanh', return_sequences=True))  ## , input_shape=(?,?))) without a Normalizer layer\n",
    "rnn_model.add(SimpleRNN(units=20, activation='tanh'))  ## \n",
    "rnn_model.add(Dense(10, activation = 'relu')) ## add 1 or more 'relu' layers\n",
    "# model.add(layers.Dropout(0.3)) ## if RNN model over-fit\n",
    "rnn_model.add(Dense(n_pred, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbe63f-114d-4717-a404-0aa7b96de1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile model with 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524eb0a-0117-4006-af85-9f8235e96cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compiling with 'rmsprop' rather than 'adam' (recommended)\n",
    "rnn_model.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "                 metrics='mape')  # Recommended optimizer for RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a685f57-01a6-4405-8b38-0cc3c7fa5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739df8e1-5a54-4634-a074-e644a6a796a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661159e6-4eb3-48cc-b11d-fff40fb81a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3. Training\n",
    "es = EarlyStopping(monitor = 'val_loss',\n",
    "                   patience = 10,\n",
    "                   verbose = 0,\n",
    "                   restore_best_weights = True)\n",
    "# The fit\n",
    "rnn_model.fit(X_train,\n",
    "          y_train, \n",
    "          validation_split=0.1, # Auto split for validation data\n",
    "              ## validation_data = (X_val, y_val), # To be created manually if needed\n",
    "          batch_size = 16,\n",
    "          epochs = 200,\n",
    "          callbacks = [es],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e901218-eb1c-4d85-b40e-9beda6c3c548",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1267f1-8a86-4f8b-82f5-01478bc0d350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Evaluating\n",
    "# The prediction (one per sequence/city)\n",
    "y_pred = rnn_model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f576952-8105-43b3-9d97-39d19277c207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c615d0-d83c-4b7d-b076-b914179fb0ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a68310-d512-4825-a2c4-21cb68e5f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your code below\n",
    "assert y_pred.shape == (n_seq_test, n_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "9c7d4b3da1e137aeabc4fd6b55dede4bb1c85dbdc50880a4fde3d2604903e3dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
