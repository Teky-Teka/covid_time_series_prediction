{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cac72ae-9be5-43d4-87d3-b2319a0f757b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning Time Series COVID-19 Cases Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a246bb7-0cdf-4939-a4e9-870f871706f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd5297-79e4-4864-bb68-8deb37dbc70a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dependencies importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c99354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload imported module every time a jupyter cell is executed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de425903-9365-4407-8ae8-9b20a6e41dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "# from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import requests\n",
    "import pandas_profiling\n",
    "from typing import overload\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop \n",
    "from covid_time_series_prediction.ml_logic import preprocessor\n",
    "from covid_time_series_prediction.dp_logic.sequencing import subsample_sequence, get_X_y, get_X_y_2\n",
    "from covid_time_series_prediction.dp_logic.RNN_model import model_run\n",
    "from covid_time_series_prediction.ml_logic.preprocessor import train_test_set\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c8b3bb-c12b-43a3-9dda-7bbd905f3622",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/raw_data/'\n",
    "\n",
    "df_raw_gov_response = pd.read_csv(data_dir + 'government_response_index_avg.csv')\n",
    "df_raw_health = pd.read_csv(data_dir + 'containment_health_index_avg.csv')\n",
    "df_raw_economic = pd.read_csv(data_dir + 'economic_support_index.csv')\n",
    "\n",
    "#### Vaccination\n",
    "df_raw_vaccination = pd.read_csv(data_dir + 'vaccinations.csv')\n",
    "df_raw_ages = pd.read_csv(data_dir + 'vaccinations-by-age-group.csv')\n",
    "\n",
    "\n",
    "#### Data Frame target\n",
    "df_raw_cases = pd.read_csv(data_dir + 'confirmed_cases.csv')\n",
    "df_raw_deaths = pd.read_csv(data_dir + 'confirmed_deaths.csv')\n",
    "\n",
    "#### Data multiple\n",
    "df_raw_school_closing=pd.read_csv(data_dir + 'c1m_school_closing.csv')\n",
    "df_raw_workplace_closing=pd.read_csv(data_dir + 'c2m_workplace_closing.csv')\n",
    "df_raw_cancel_public_event=pd.read_csv(data_dir + 'c3m_cancel_public_events.csv')\n",
    "df_raw_restriction_on_gathering=pd.read_csv(data_dir + 'c4m_restrictions_on_gatherings.csv')\n",
    "df_raw_stay_at_home=pd.read_csv(data_dir + 'c6m_stay_at_home_requirements.csv')\n",
    "df_raw_international_travel=pd.read_csv(data_dir + 'c6m_stay_at_home_requirements.csv')\n",
    "df_raw_goverment_response=pd.read_csv(data_dir + 'government_response_index_avg.csv')\n",
    "df_raw_facial_covering=pd.read_csv(data_dir + 'h6m_facial_coverings.csv')\n",
    "df_raw_vacination_policy=pd.read_csv(data_dir + 'h7_vaccination_policy.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f43d38",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Read out CSV** and **Set dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecf123-5e8d-4e1e-b337-e0164c78fa4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## DataFrames setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b592f6-4433-43a6-9641-43e70f42c17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### CSV Data out project directory\n",
    "csv_dir = '../data/out_csv/'\n",
    "# ! unzip {csv_dir}usa_index\n",
    "# ! unzip {csv_dir}usa_indicator\n",
    "# ! rm ECG_data.zip\n",
    "df_fr_index =  pd.read_csv(csv_dir + 'index_FRA.csv')\n",
    "df_fr_indicator =  pd.read_csv(csv_dir + 'indicator_FRA.csv')\n",
    "df_fr_index, df_fr_indicator\n",
    "\n",
    "\n",
    "# Sumedha csv test\n",
    "df_ts_fra_index =  df_fr_index.copy()\n",
    "df_ts_fra_indicator =  df_fr_indicator.copy()\n",
    "\n",
    "df_ts_fra_index.head(), df_ts_fra_indicator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a8973-c402-4ec9-93e8-e9254458cc1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ts_fra_indicator = df_ts_fra_indicator.set_index('date')\n",
    "X_ts_fra_indicator = df_ts_fra_indicator.drop(columns=['total_deaths','new_deaths','new_cases'])\n",
    "y_ts_fra_indicator = df_ts_fra_indicator['total_deaths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122911e-70c8-4131-bf2f-8db270b3ac93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TENSORFLOW & RNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636afbb-aab0-4500-897b-311961289203",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Recurrent Neural Network (sequences data) modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f081b-7ee6-405b-8e13-04bf267ac2e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Samples/Sequences, Observations, Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6427dc3-25b3-4a5a-abba-20e92d67ab1b",
   "metadata": {},
   "source": [
    "X.shape = (n_SEQUENCES, n_OBSERVATIONS, n_FEATURES) and y = RNN(X) where $X_{i,j}^{t}$\n",
    "\n",
    "with $_{i}$ is the sample/sequence, $_{j}$ is the feature measured and  $^{t}$ is the time at which the observation is seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8151dc-1f0e-4981-91a0-c1164230af26",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- **retrieve dataset** from Sumedha & Alberto\n",
    "\n",
    "    - **clean dataset**: \n",
    "        \n",
    "        - **drop first lines == 0** *(before Covid arrived)*\n",
    "        \n",
    "        - **check Nan**: \n",
    "- **strategy 1 country by country** sequences split as follow:\n",
    "\n",
    "- **strategy 2 one sequence per country**:\n",
    "    - **split X train, set** \n",
    "    - **Pad sequences**\n",
    "    - **create one csv per country**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32848eaa-a889-47ee-972c-e9f2e54214cc",
   "metadata": {},
   "source": [
    "## Training strategies:\n",
    "- Get NB dataset (cleaned) from Alberto & Sumedha\n",
    "- 1/ Indicator in precentage %\n",
    "- 2/ Indicator as categorical labels\n",
    "- Run same RNN model in parallel with Kim & Thomas\n",
    "- Identify best dataset\n",
    "- Parameters to fit:\n",
    "    - increase **nb of sequences**\n",
    "    - train series modulation (ex: [50, 150, 200, 300, 400 nb of days = n_obs]) < take time to compute\n",
    "    - **learning_rate** in Optimizer(parameters)\n",
    "    - model layers architecture (**simple** -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "        > LSTM\n",
    "        > Dense\n",
    "       (> LSTM\n",
    "        > LSTM\n",
    "        > Dense)\n",
    "     >> **try to overfit** the model with the loss (train over val) or (early_stopping)\n",
    "     >> **(X_val, y_val)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775435d-8b7a-4742-bcb2-a76e1c2ffb1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **RNN** models on **FRA** country with **Alberto**'s datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648961ed-ee19-4342-b137-8f5029082404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_seq\t\t 200 \n",
      "n_seq_val\t 40 \n",
      "n_seq_test\t 20 \n",
      "n_obs\t\t 70 \n",
      "n_feat\t\t 20\n"
     ]
    }
   ],
   "source": [
    "# Alberto train set\n",
    "n_seq = 200 ## nb of sequences (samples)\n",
    "n_obs = [70, 65, 60] # maxi = 96 (stay around 70 or more test_split)\n",
    "n_obs = 70 # maxi = 96 (stay around 70 or more test_split)\n",
    "n_feat = 20 #  X_train.shape[1] # 20 feature:\n",
    "n_pred = 10 # nb of days where we can predict new daily deaths\n",
    "n_pred = 1 ## <<< REMOVE AFTER OK TESTING!\n",
    "n_seq_val = n_seq // 5 # number of sequences in test set ?\n",
    "n_seq_test = n_seq // 10 # number of sequences in test set ?\n",
    "print('n_seq\\t\\t', n_seq, '\\nn_seq_val\\t', n_seq_val, '\\nn_seq_test\\t', n_seq_test, '\\nn_obs\\t\\t', n_obs, '\\nn_feat\\t\\t', n_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3245d337-90d7-47b1-a4ee-b508e8731c39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Splitting\n",
    "\n",
    "Split the dataset into training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe70c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape\t (673, 21) \t->\ty_train shape\t (673,) \n",
      "X_val.shape\t (192, 21) \t->\ty_val shape\t (192,) \n",
      "X_test.shape\t (97, 21) \t->\ty_test shape\t (97,)\n"
     ]
    }
   ],
   "source": [
    "# Alberto train set\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_set('Vietnam', split_train=0.7, split_val=0.9)\n",
    "print('X_train.shape\\t', X_train.shape, '\\t->\\ty_train shape\\t', y_train.shape, '\\nX_val.shape\\t', X_val.shape, '\\t->\\ty_val shape\\t', y_val.shape, '\\nX_test.shape\\t', X_test.shape, '\\t->\\ty_test shape\\t', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4fba2-9562-49eb-9b94-7c5ab57fd163",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create sequences (`X`,`y`, `X_len`, `y_len`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e6437-7538-4c29-b8d9-d00d4d804064",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Generates an entire dataset of multiple subsamples with shape $(X, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3af4e7e-d602-4fcd-a36a-942ab4dc0b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_seq_test / n_obs / n_feat 20 70 20 \n",
      "X_test.shape (20, 70, 21) y_test.shape (20, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_X_y_2(X_test, y_test, X_len=n_obs, y_len=n_pred, n_sequences=n_seq_test)\n",
    "print('n_seq_test / n_obs / n_feat', n_seq_test, n_obs, n_feat, '\\nX_test.shape', X_test.shape, 'y_test.shape', y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7826c700-4273-4cd3-b7d7-4c3cca2b3582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_seq / n_obs / n_feat 200 70 20 \n",
      "X_train.shape (200, 70, 21) y_train.shape (200, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_X_y_2(X_train, y_train, X_len=n_obs, y_len=n_pred, n_sequences=n_seq)\n",
    "print('n_seq / n_obs / n_feat', n_seq, n_obs, n_feat, '\\nX_train.shape', X_train.shape, 'y_train.shape', y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b232f85-3b62-4392-ad62-6cab9507d5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_seq_val / n_obs / n_feat 40 70 20 \n",
      "X_val.shape (40, 70, 21) y_val.shape (40, 1)\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val = get_X_y_2(X_val, y_val, X_len=n_obs, y_len=n_pred, n_sequences=n_seq_val)\n",
    "print('n_seq_val / n_obs / n_feat', n_seq_val, n_obs, n_feat, '\\nX_val.shape', X_val.shape, 'y_val.shape', y_val.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe229ed-38be-485e-9314-5a3c04da8847",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### How to split sequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49128bf-f5e8-4319-8635-fa1f63c29ceb",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "- randomly or\n",
    "\n",
    "- manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad867c99-9dd9-4dc5-9cda-de741bf57ca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **train_rnn_model(model, patience=2, epochs=200):**\n",
    "\n",
    "function to generates an entire dataset of multiple subsamples suitable for RNN, that is, $(X, y)$ of shape:\n",
    "\n",
    "```python\n",
    "X.shape = (n_sequences, length, n_features)\n",
    "y.shape = (n_sequences, )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ece011-197d-439e-b405-ee2370c9773d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model #4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f844bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape\t (200, 70, 21) \t->\ty_train shape\t (200, 1) \n",
      "X_val.shape\t (40, 70, 21) \t->\ty_val shape\t (40, 1) \n",
      "X_test.shape\t (20, 70, 21) \t->\ty_test shape\t (20, 1)\n",
      "type(X_train)\t <class 'numpy.ndarray'> \t->\ttype(y_train)\t <class 'numpy.ndarray'> \n",
      "type(X_val)\t <class 'numpy.ndarray'> \t->\ttype(y_val)\t <class 'numpy.ndarray'> \n",
      "type(X_test)\t <class 'numpy.ndarray'> \t->\ttype(y_test)\t <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape\\t', X_train.shape, '\\t->\\ty_train shape\\t', y_train.shape, '\\nX_val.shape\\t', X_val.shape, '\\t->\\ty_val shape\\t', y_val.shape, '\\nX_test.shape\\t', X_test.shape, '\\t->\\ty_test shape\\t', y_test.shape)\n",
    "print('type(X_train)\\t', type(X_train), '\\t->\\ttype(y_train)\\t', type(y_train), '\\ntype(X_val)\\t', type(X_val), '\\t->\\ttype(y_val)\\t', type(y_val), '\\ntype(X_test)\\t', type(X_test), '\\t->\\ttype(y_test)\\t', type(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e0b83-5aec-4a29-bc8e-6a5c34b05ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### LET TEST IT NOW!\n",
    "\n",
    "model_run(country_name=\n",
    "          'France', n_seq=200, n_obs=[60], n_feat=20, n_pred=1, split_train=0.7, split_val=0.9, learning_rates=[0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209677d3-65b8-4c36-b3cc-aef04126b8bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_run(country_name='France', n_seq=200, n_obs=[60], n_feat=20, n_pred=1, split_train=0.7, split_val=0.9, learning_rates=[0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0c011-e6d5-442a-b6cb-29d076a9d04a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **RNN** models on **FRA** country with **Sumedha**'s datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21372d-9cd7-4884-b42b-012437d3337e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sumedha train set\n",
    "n_seq = 200 ## nb of sequences (samples)\n",
    "n_obs = [70, 65, 60] # maxi = 96 (stay around 70 or more test_split)\n",
    "n_obs = 70 # maxi = 96 (stay around 70 or more test_split)\n",
    "n_feat = 20 #  X_train.shape[1] # 20 feature:\n",
    "n_pred = 10 # nb of days where we can predict new daily deaths\n",
    "n_pred = 1 ## <<< REMOVE AFTER OK TESTING!\n",
    "n_seq_val = n_seq // 5 # number of sequences in test set ?\n",
    "n_seq_test = n_seq // 10 # number of sequences in test set ?\n",
    "print('n_seq\\t\\t', n_seq, '\\nn_seq_val\\t', n_seq_val, '\\nn_seq_test\\t', n_seq_test, '\\nn_obs\\t\\t', n_obs, '\\nn_feat\\t\\t', n_feat)\n",
    "\n",
    "split_train=0.7 ; split_val=0.9\n",
    "\n",
    "# 0. The Normalization Layer\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(X_ts_fra_indicator)\n",
    "\n",
    "train = int((len(X_ts_fra_indicator)*split_train))\n",
    "val = int(len(X_ts_fra_indicator)*split_val)\n",
    "\n",
    "X_train = X_ts_fra_indicator[:train]\n",
    "y_train = y_ts_fra_indicator[:train]\n",
    "\n",
    "X_val = X_ts_fra_indicator[train:val]\n",
    "y_val = y_ts_fra_indicator[train:val]\n",
    "\n",
    "X_test = X_ts_fra_indicator[val:]\n",
    "y_test = y_ts_fra_indicator[val:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d0d52-9122-40a3-84fe-8e0cbbf5a140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_run(country_name='France', n_seq=200, n_obs=[62, 61, 60], n_feat=20, n_pred=1, split_train=0.7, split_val=0.9, learning_rates=[0.1, 0.01, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70373313-8bfb-47ea-90a7-4c193c5cdfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run(country_name='France', n_seq=200, n_obs=[62, 61, 60], n_feat=20, n_pred=1, split_train=0.7, split_val=0.9, learning_rates=[0.1, 0.05, 0.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a652e-f059-4adf-bf05-62b7120a24d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RNN model #3 architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d57380-7866-4ec5-8e40-b86653234646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Architecture\n",
    "\"\"\"   - 3rd model layers architecture (simple -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "> LSTM\n",
    "\"\"\"\n",
    "rnn_model_3 = Sequential()\n",
    "rnn_model_3.add(normalizer) # Using the Normalization layer to standardize the datapoints during the forward pass\n",
    "# Input len(train) (input_shape=(?,?))\n",
    "rnn_model_3.add(LSTM(units=30, activation='tanh'))  ## , input_shape=(?,?))) without a Normalizer layer\n",
    "# output return sequences = True\n",
    "rnn_model_3.add(Dense(10, activation = 'relu')) ## add 1 or more 'relu' layers\n",
    "# Output 10 only, no more RNN just dropout()\n",
    "# rnn_model_3.add(layers.Dropout(0.3)) ## if RNN model over-fit\n",
    "rnn_model_3.add(Dense(n_pred, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e901218-eb1c-4d85-b40e-9beda6c3c548",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model #1 evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1267f1-8a86-4f8b-82f5-01478bc0d350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Evaluating\n",
    "# The prediction (one per sequence/city)\n",
    "y_pred = rnn_model.predict(X_test) \n",
    "print(y_pred.shape)\n",
    "# Distribution of the predictions\n",
    "pd.DataFrame(y_pred).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c615d0-d83c-4b7d-b076-b914179fb0ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time Series Forecasting with model #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbe63f-114d-4717-a404-0aa7b96de1b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile model #3 with 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524eb0a-0117-4006-af85-9f8235e96cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compiling with 'rmsprop' rather than 'adam' (recommended)\n",
    "optimizer = RMSprop(\n",
    "                learning_rate=0.001,\n",
    "                rho=0.9,\n",
    "                momentum=0.0,\n",
    "                epsilon=1e-07,\n",
    "                centered=False\n",
    "            )\n",
    "rnn_model_3.compile(loss='mse',\n",
    "              optimizer= optimizer, # optimizer='rmsprop'    <- adapt learning rate\n",
    "                 metrics='mape')  # Recommended optimizer for RNNs\n",
    "rnn_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a685f57-01a6-4405-8b38-0cc3c7fa5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739df8e1-5a54-4634-a074-e644a6a796a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571254c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = train_rnn_model(rnn_model, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, patience=5, epochs=200)\n",
    "plt.plot(history.history['mape'])\n",
    "plt.plot(history.history['val_mape'])\n",
    "plt.show();\n",
    "type(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trai### Train model #1n_series = [50, 150, 200, 300, 400]\n",
    "overfit_es =   [2, 6, 6, 5, 6 ]\n",
    "print('type(overfit_es), overfit_es', type(overfit_es), overfit_es)\n",
    "# if overfit_es:\n",
    "#     print(\"early stopping\")\n",
    "#     history = train_rnn_model(patience=overfit_es)\n",
    "# else:\n",
    "# print(\"No early stopping\")\n",
    "for i in range(len(train_series)):\n",
    "    history = train_rnn_model(model=rnn_model_2, epochs=train_series[i], patience=overfit_es[i])\n",
    "    plt.plot(history.history['mape'])\n",
    "    plt.plot(history.history['val_mape'])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1950356",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RNN model #3 architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b325a69",
   "metadata": {},
   "source": [
    "#### 🚀 The **LSTM (= Long Short Term Memory)** with their ability to *avoid the vanishing gradient problem*, should be preferred over a SimpleRNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Architecture\n",
    "\"\"\"   - 3rd model layers architecture (simple -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "> LSTM\n",
    "\"\"\"\n",
    "rnn_model_3 = Sequential()\n",
    "rnn_model_3.add(normalizer) # Using the Normalization layer to standardize the datapoints during the forward pass\n",
    "# Input len(train) (input_shape=(?,?))\n",
    "rnn_model_3.add(LSTM(units=30, activation='tanh'))  ## , input_shape=(?,?))) without a Normalizer layer\n",
    "# output return sequences = True\n",
    "rnn_model_3.add(Dense(10, activation = 'relu')) ## add 1 or more 'relu' layers\n",
    "# Output 10 only, no more RNN just dropout()\n",
    "# rnn_model_3.add(layers.Dropout(0.3)) ## if RNN model over-fit\n",
    "rnn_model_3.add(Dense(n_pred, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ae1226",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile model #3 with 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f878a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compiling with 'rmsprop' rather than 'adam' (recommended)\n",
    "optimizer = RMSprop(\n",
    "                learning_rate=0.001,\n",
    "                rho=0.9,\n",
    "                momentum=0.0,\n",
    "                epsilon=1e-07,\n",
    "                centered=False\n",
    "            )\n",
    "rnn_model_3.compile(loss='mse',\n",
    "              optimizer= optimizer, # optimizer='rmsprop'    <- adapt learning rate\n",
    "                 metrics='mape')  # Recommended optimizer for RNNs\n",
    "rnn_model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1470a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1673f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RNN model #3 architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92739ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The Architecture\n",
    "\"\"\"   - 3rd model layers architecture (simple -> complex) (less data -> more data) (print(loss) function check lecture)\n",
    "> LSTM\n",
    "\"\"\"\n",
    "rnn_model_3 = Sequential()\n",
    "rnn_model_3.add(normalizer) # Using the Normalization layer to standardize the datapoints during the forward pass\n",
    "# Input len(train) (input_shape=(?,?))\n",
    "rnn_model_3.add(LSTM(units=30, activation='tanh'))  ## , input_shape=(?,?))) without a Normalizer layer\n",
    "# output return sequences = True\n",
    "rnn_model_3.add(Dense(10, activation = 'relu')) ## add 1 or more 'relu' layers\n",
    "# Output 10 only, no more RNN just dropout()\n",
    "# rnn_model_3.add(layers.Dropout(0.3)) ## if RNN model over-fit\n",
    "rnn_model_3.add(Dense(n_pred, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c972bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile model #3 with 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f0a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compiling with 'rmsprop' rather than 'adam' (recommended)\n",
    "optimizer = RMSprop(\n",
    "                learning_rate=0.001,\n",
    "                rho=0.9,\n",
    "                momentum=0.0,\n",
    "                epsilon=1e-07,\n",
    "                centered=False\n",
    "            )\n",
    "rnn_model_3.compile(loss='mse',\n",
    "              optimizer= optimizer, # optimizer='rmsprop'    <- adapt learning rate\n",
    "                 metrics='mape')  # Recommended optimizer for RNNs\n",
    "rnn_model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8cc51a-a8a3-4a61-9c9e-96317f159d50",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923f50a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min(history.history['mape'])\n",
    "\n",
    "# print(\"adjust early stopping\")\n",
    "# overfit_es = [d[0]+1 for d in enumerate(history.history['mape']) if d[1] == min(history.history['mape'])][0]\n",
    "# overfit_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c43e359-c428-43f9-9369-f0804a5acdac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min(history.history['mape']), max(history.history['mape']), history.history['mape'] # blue line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f6eb0-e734-48c4-a455-49949ea62a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max(history.history['val_mape']), history.history['val_mape'] # orange line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba3da5-6613-418e-9919-2f7d50e0078e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Model #1 evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed1ac5-3b8a-4049-abe8-9431de2121c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Evaluating\n",
    "# The prediction (one per sequence/city)\n",
    "y_pred = rnn_model.predict(X_test) \n",
    "print(y_pred.shape)\n",
    "# Distribution of the predictions\n",
    "pd.DataFrame(y_pred).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32232f29-fc87-49fc-9f6f-11dcb25a9f92",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time Series Forecasting with model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a68310-d512-4825-a2c4-21cb68e5f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your code below\n",
    "assert y_pred.shape == (n_seq_test, n_pred)\n",
    "# Distribution of the real values y_train\n",
    "pd.DataFrame(y_train).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8cad73-73e8-4211-908a-3789b7a03497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the real values y_train\n",
    "pd.DataFrame(y_train).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd17d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trai### Train model #1n_series = [50, 150, 200, 300, 400]\n",
    "overfit_es =   [2, 6, 6, 5, 6 ]\n",
    "print('type(overfit_es), overfit_es', type(overfit_es), overfit_es)\n",
    "# if overfit_es:\n",
    "#     print(\"early stopping\")\n",
    "#     history = train_rnn_model(patience=overfit_es)\n",
    "# else:\n",
    "# print(\"No early stopping\")\n",
    "for i in range(len(train_series)):\n",
    "    history = train_rnn_model(model=rnn_model_2, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, epochs=train_series[i], patience=overfit_es[i])\n",
    "    plt.plot(history.history['mape'])\n",
    "    plt.plot(history.history['val_mape'])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f576952-8105-43b3-9d97-39d19277c207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_index=data_index.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6cdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e588d92b224e11b16adbbadd39936dea13a6488171770263a646fc57f44563d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
